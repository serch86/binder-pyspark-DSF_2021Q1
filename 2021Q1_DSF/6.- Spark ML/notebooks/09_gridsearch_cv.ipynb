{"metadata": {"language_info": {"pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "version": "3.5.2"}, "kernelspec": {"display_name": "d1-spark2python3", "language": "python", "name": "spark-python-d1-spark2python3"}, "toc": {"title_cell": "Table of Contents", "skip_h1_title": false, "number_sections": true, "toc_section_display": true, "base_numbering": 1, "toc_window_display": false, "toc_cell": false, "sideBar": true, "title_sidebar": "Contents", "toc_position": {}, "nav_menu": {}}}, "cells": [{"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 5, "outputs": [], "source": ["SANDBOX_NAME = '' # Sandbox Name\n", "DATA_PATH = \"/data/sandboxes/\"+SANDBOX_NAME+\"/data/\""]}, {"metadata": {}, "source": ["\n", "\n", "# Ejemplo de Param Grid\n", "\n", "Para encontrar los mejores hiperapar\u00e1metros para un modelo, se puede definir un conjunto de posibles valores para cada hiperpar\u00e1metro, y crear un programa que entrene modelos con cada combinaci\u00f3n posible de ellos, y almacene el mejor modelo dada una metrica. Adem\u00e1s se puede mejorar junto con la t\u00e9cnica de Validaci\u00f3n Cruzada."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 6, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Primer paso, cargar algunos datos de prueba e inspeccionar."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 7, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 8, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Busquemos valores nulos en todas las columnas y descartemos filas que tengan nulos en ellas. Ya vimos anteriormente c\u00f3mo trabajar con valores nulos."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 9, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Tras limpiar el dataset de nulos, podemos continuar preparando las variables y entrenando un modelo.\n", "Para mantenerlo sencillo, apuntaremos las columnas binarias para evitar aplicarles onehot.\n", "\n", "- Aplicamos el string indexer a todas las columnas tipo string (estamos asumiendo aqu\u00ed que todas las columnas tipo string son categ\u00f3ricas)\n", "- Aplicamos one hot encoder a todas las variables string no binarias\n", "- Tras el string indexer Y el one hot encoder en las variables no binarias, removemos la columna resultado del string indexer para quedarnos s\u00f3lo con la salida del one hot encoder. Y le cambiamos el nombre a la salida del one hot encoder a *_encoded*. As\u00ed s\u00f3lo tendremos una variable *_encoded* para cada variable transformada en lugar de tener en el dataset el resultado del string indexer Y el del one hot encoder."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 10, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "cell_type": "code", "execution_count": 11, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 12, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Listamos columnas de entrenamiento y seleccionamos columna de target"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 13, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 14, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Son demasiadas variables para introducir al modelo. Calculamos la correlaci\u00f3n con las num\u00e9ricas originales (que no son categ\u00f3ricas indexadas)"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 15, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Hacemos un random forest para sacar la importancia de las variables con todas las disponibles:"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 16, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "cell_type": "code", "execution_count": 17, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "cell_type": "code", "execution_count": 18, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "cell_type": "code", "execution_count": 19, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Primera aproximaci\u00f3n para crear un modelo: crear obligatorio VectorAssembler, dividir los datos en train y test y entrenar la primera versi\u00f3n con hipermar\u00e1metros por defecto. Seleccionaremos las 10 variables m\u00e1s importantes. Despu\u00e9s evaluaremos nuestro modelo (usaremos accuracy)"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 20, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 21, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 22, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Podemos ver el n\u00famero de \u00e1rboles de nuestro random forest usando el atributo getNumTrees"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 23, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "Pero, \u00bfpodemos afirmar que este modelo fue entrenado con los mejores hiperpar\u00e1metros? Se podr\u00edan listar muchas combinaciones de ellos, lo que significa mucho trabajo manual. Pero no hay que preocuparse, para manejar esta situaci\u00f3n Spark incorpora **ParamGrid**. \n", "\n", "S\u00f3lo hay que definir los valores de cada hiperpar\u00e1metro que queremos probar en ParamGridBuilder y utilizar el objeto resultante en el par\u00e1metro `estimatorParamMaps` cuando se define el CrossValidator.\n", "\n", "En este caso, probaremos todas las combinaciones de:\n", "\n", "- Number of trees: [10,50,100,200]\n", "- Max depth: [3, 5, 7]"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 24, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 25, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 26, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "# Ejercicio 1\n", "\n", "Dado el siguiente DataFrame:"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 27, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "1) Calcula las dimensiones del Data Frame"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 28, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "2) Determina las clases de la base de datos, y su proporci\u00f3n"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 29, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "cell_type": "code", "execution_count": 30, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "3) Calcula el numero de valores no nulos, media, desviacion estandar, minimo y maximo de cada variable."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 31, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "4) Convierte la columna \"Class\" a double"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 32, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "5) Divide el dataset en train y test, y comprueba si se mantiene la proporcion de las clases."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 33, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "6) Determina las columnas a utilizar como entradas del modelo"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 35, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "cell_type": "code", "execution_count": 36, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "cell_type": "code", "execution_count": 41, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "7) Entrena una regresi\u00f3n logistica usando Pipeline y evalua el modelo resultante calculando la AUC, f1, la tasa de acierto y la matriz de confusi\u00f3n  para train y test."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 39, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 42, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "8) Entrena un RandomForestClassifier usando Pipeline y evalua el modelo resultante calculando la AUC, la tasa de acierto y la matriz de confusi\u00f3n  para train y test."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 43, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 44, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "9) Utiliza una CV 5-fold con grid search para determinar los mejores parametros del RandomForestClassifier utilizando como metrica la f1. Prueba los parametros _maxDepth_ y _numTrees_."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 45, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 46, "outputs": [], "source": ["# Respuesta aqui"]}, {"metadata": {}, "source": ["\n", "\n", "10) Cuales son los valores de los parametros usados en el grid search"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 47, "outputs": [], "source": ["# Respuesta aqui"]}], "nbformat": 4, "nbformat_minor": 2}