{"metadata": {"language_info": {"pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "version": "3.5.2"}, "@webio": {"lastCommId": "0f1cc61b6bb340ecac2a5cea7f61b70a", "lastKernelId": "6f462f9a-2121-4a15-9d4f-d6566384cce2"}, "kernelspec": {"display_name": "d1-spark2python3", "language": "python", "name": "spark-python-d1-spark2python3"}, "toc": {"title_cell": "Table of Contents", "skip_h1_title": false, "number_sections": true, "toc_section_display": true, "base_numbering": 1, "toc_window_display": false, "toc_cell": false, "sideBar": true, "title_sidebar": "Contents", "toc_position": {}, "nav_menu": {}}}, "cells": [{"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 1, "outputs": [], "source": ["SANDBOX_NAME = ''# Sandbox Name\n", "DATA_PATH = \"/data/sandboxes/\" + SANDBOX_NAME + \"/data/\""]}, {"metadata": {}, "source": ["\n", "\n", "# Spark ML\n", "\n", "Cargamos un dataset con informaci\u00f3n de la distribuci\u00f3n de los p\u00edxeles para cada una de las letras del alfabeto escritas en may\u00fasculas. El objetivo ser\u00e1 predecir si el caracter en cuesti\u00f3n es una vocal o una consonante. En el proceso se aprender\u00e1n los pasos generales a seguir para solucionar un problema de este tipo con Spark ML.\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "### Crear SparkSession"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 2, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.sql import SparkSession\n", "\n", "spark = SparkSession.builder.getOrCreate()"]}, {"metadata": {}, "source": ["\n", "\n", "### Importar librerias"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 3, "outputs": [], "source": ["# Respuesta\n", "\n", "import pandas as pd"]}, {"metadata": {}, "source": ["\n", "\n", "### Cargar datos y comprobar schema"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 4, "outputs": [], "source": ["# Respuesta\n", "\n", "letters = spark.read.csv(DATA_PATH+'data/letter.txt', sep=',', header=True, inferSchema=True)"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 5, "outputs": [{"output_type": "stream", "text": ["root\n", " |-- x_box_integer: integer (nullable = true)\n", " |-- y_box_integer: integer (nullable = true)\n", " |-- width_integer: integer (nullable = true)\n", " |-- high_integer: integer (nullable = true)\n", " |-- onpix_integer: integer (nullable = true)\n", " |-- x_bar_integer: integer (nullable = true)\n", " |-- y_bar_integer: integer (nullable = true)\n", " |-- x2bar_integer: integer (nullable = true)\n", " |-- y2bar_integer: integer (nullable = true)\n", " |-- xybar_integer: integer (nullable = true)\n", " |-- x2ybr_integer: integer (nullable = true)\n", " |-- xy2br_integer: integer (nullable = true)\n", " |-- x_ege_integer: integer (nullable = true)\n", " |-- xegvy_integer: integer (nullable = true)\n", " |-- y_ege_integer: integer (nullable = true)\n", " |-- yegvx_integer: integer (nullable = true)\n", " |-- class: string (nullable = true)\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "letters.printSchema()"]}, {"metadata": {}, "source": ["\n", "\n", "### Crear nueva variable objetivo\n", "\n", "La variable objetivo ahora mismo es cada una de las letras del abecedario en may\u00fascula. Se crea nueva variable con el nombre 'flag' que tome el valor 1 si se trata de una vocal y 0 en caso contrario, para convertir el problema en un problema de clasificaci\u00f3n binaria."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "text": ["+-----+-----+\n", "|class|count|\n", "+-----+-----+\n", "|    A|  789|\n", "|    B|  766|\n", "|    C|  736|\n", "|    D|  805|\n", "|    E|  768|\n", "|    F|  775|\n", "|    G|  773|\n", "|    H|  734|\n", "|    I|  755|\n", "|    J|  747|\n", "|    K|  739|\n", "|    L|  761|\n", "|    M|  792|\n", "|    N|  783|\n", "|    O|  753|\n", "|    P|  803|\n", "|    Q|  783|\n", "|    R|  758|\n", "|    S|  748|\n", "|    T|  796|\n", "|    U|  813|\n", "|    V|  764|\n", "|    W|  752|\n", "|    X|  787|\n", "|    Y|  786|\n", "|    Z|  734|\n", "+-----+-----+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "letters.groupBy('class').count().orderBy('class').show(500)"]}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 7, "outputs": [{"output_type": "stream", "text": ["+-----+---+\n", "|class|tag|\n", "+-----+---+\n", "|    X|0.0|\n", "|    L|0.0|\n", "|    A|1.0|\n", "|    B|0.0|\n", "|    R|0.0|\n", "|    G|0.0|\n", "|    Y|0.0|\n", "|    N|0.0|\n", "|    F|0.0|\n", "|    E|1.0|\n", "|    I|1.0|\n", "|    K|0.0|\n", "|    M|0.0|\n", "|    D|0.0|\n", "|    V|0.0|\n", "|    S|0.0|\n", "|    Z|0.0|\n", "|    U|1.0|\n", "|    Q|0.0|\n", "|    W|0.0|\n", "|    H|0.0|\n", "|    J|0.0|\n", "|    T|0.0|\n", "|    O|1.0|\n", "|    C|0.0|\n", "|    P|0.0|\n", "+-----+---+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "import pyspark.sql.functions as F\n", "from pyspark.sql.functions import col\n", "from pyspark.sql.types import DoubleType\n", "\n", "letters = letters.withColumn('tag', col('class').isin('A', 'E', 'I', 'O', 'U').cast('double'))\n", "letters.select('class', 'tag').distinct().show(500)"]}, {"metadata": {}, "source": ["\n", "\n", "### Primeros pasos\n", "\n", "Primeros pasos: nulos y vector assembler"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Empezaremos con la comprobaci\u00f3n y tratamiento de nulos."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 8, "outputs": [{"output_type": "stream", "text": ["column: x_box_integer Nulls: 0\n", "column: y_box_integer Nulls: 0\n", "column: width_integer Nulls: 0\n", "column: high_integer Nulls: 0\n", "column: onpix_integer Nulls: 0\n", "column: x_bar_integer Nulls: 0\n", "column: y_bar_integer Nulls: 0\n", "column: x2bar_integer Nulls: 0\n", "column: y2bar_integer Nulls: 0\n", "column: xybar_integer Nulls: 0\n", "column: x2ybr_integer Nulls: 0\n", "column: xy2br_integer Nulls: 1\n", "column: x_ege_integer Nulls: 0\n", "column: xegvy_integer Nulls: 0\n", "column: y_ege_integer Nulls: 0\n", "column: yegvx_integer Nulls: 0\n", "column: class Nulls: 0\n", "column: tag Nulls: 0\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "for column in letters.columns:\n", "    print('column: {} Nulls: {}'.format(column, letters.filter(col(column).isNull()).count()))"]}, {"metadata": {}, "source": ["\n", "\n", "Habr\u00eda que pensar si:\n", "    1. Es v\u00e1lido/tiene sentido que pueda existir alg\u00fan nulo en sus datos.\n", "    2. Qu\u00e9 hacemos con estos nulos.\n", "        - \u00bfLos imputamos?\n", "        - \u00bfLos tiramos?\n", "        - \u00bfDe qu\u00e9 depende?\n", "\n", "En nuestro caso, vamos a tirar el \u00fanico caso con un nulo, por simplicidad."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 10, "outputs": [], "source": ["# Respuesta\n", "\n", "letters = letters.na.drop()"]}, {"metadata": {}, "source": ["\n", "\n", "Tras remover todos los nulos, usamos el VectorAssembler con todas las variables excepto las objetivo (la nueva variable objetivo *tag* y la original *class*).\n", "\n", "Asumimos aqu\u00ed que todas las variables son num\u00e9ricas y que las queremos usar como input para nuestro modelo."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 11, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.feature import VectorAssembler\n", "\n", "vectorassembler = VectorAssembler(inputCols=[_ for _ in letters.columns if _ not in  ('tag', 'class')], \n", "                                  outputCol='assembled_features')\n", "letters = vectorassembler.transform(letters)"]}, {"metadata": {}, "source": ["\n", "\n", "### Selecci\u00f3n de variables"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Vamos a hacer lo que vimos en el Notebook de selecci\u00f3n de variables\n", "\n", "Vamos a realizar la selecci\u00f3n de variables en funci\u00f3n de la importancia que le otorgue un algoritmo de ML.\n", "\n", "Como el resultado de este algoritmo depende de la semilla que utilicemos, vamos a realizar varias simulaciones y a generar la media de los resultados en cada una."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 17, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.classification import RandomForestClassifier\n", "import random\n", "\n", "random_seed = 4\n", "num_iter = 10\n", "\n", "random.seed(random_seed)\n", "\n", "random_seeds=set([random.randint(0,10000) for _ in range(num_iter)])\n", "features_random_seed = {}"]}, {"metadata": {}, "source": ["\n", "\n", "Creamos un diccionario *features_random_seed* que es un diccionario de listas, donde cada lista contiene 1 elemento por semilla, es decir, uno por random forest. El obejtivo es quedarnos con las variables que explican el 95% de la importancia."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 18, "outputs": [], "source": ["# Respuesta\n", "\n", "for random_seed in random_seeds:\n", "    rf = RandomForestClassifier(featuresCol=vectorassembler.getOutputCol(), labelCol='tag', seed = random_seed)\n", "    rf_model = rf.fit(letters)\n", "    \n", "    importances = [(index, value) for index, value in enumerate(rf_model.featureImportances.toArray().tolist())]\n", "\n", "    importances = sorted(importances, key=lambda value: value[1], reverse=True)\n", "\n", "    imp = 0\n", "    vector_assembler_cols = vectorassembler.getInputCols()\n", "    for element in importances:\n", "        feature = vector_assembler_cols[element[0]]\n", "        importance = element[1]\n", "        \n", "        if imp < 0.95:\n", "            features_random_seed[feature] = features_random_seed.get(feature, []) + [importance]\n", "        else:\n", "            features_random_seed[feature] = features_random_seed.get(feature, []) + [None]\n", "        imp += element[1]"]}, {"metadata": {}, "cell_type": "code", "execution_count": 19, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 19, "data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>0</th>\n", "      <th>1</th>\n", "      <th>2</th>\n", "      <th>3</th>\n", "      <th>4</th>\n", "      <th>5</th>\n", "      <th>6</th>\n", "      <th>7</th>\n", "      <th>8</th>\n", "      <th>9</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>high_integer</th>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>onpix_integer</th>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>width_integer</th>\n", "      <td>0.115935</td>\n", "      <td>0.119533</td>\n", "      <td>0.0701563</td>\n", "      <td>0.11351</td>\n", "      <td>0.0986111</td>\n", "      <td>0.10889</td>\n", "      <td>0.127594</td>\n", "      <td>0.0915672</td>\n", "      <td>0.126174</td>\n", "      <td>0.0959411</td>\n", "    </tr>\n", "    <tr>\n", "      <th>x2bar_integer</th>\n", "      <td>0.112091</td>\n", "      <td>0.101648</td>\n", "      <td>0.0772696</td>\n", "      <td>0.0856666</td>\n", "      <td>0.109041</td>\n", "      <td>0.082472</td>\n", "      <td>0.0967184</td>\n", "      <td>0.0767635</td>\n", "      <td>0.0827652</td>\n", "      <td>0.0602689</td>\n", "    </tr>\n", "    <tr>\n", "      <th>x2ybr_integer</th>\n", "      <td>0.112876</td>\n", "      <td>0.0780184</td>\n", "      <td>0.0937907</td>\n", "      <td>0.0834113</td>\n", "      <td>0.07267</td>\n", "      <td>0.106973</td>\n", "      <td>0.0785156</td>\n", "      <td>0.0812151</td>\n", "      <td>0.0756823</td>\n", "      <td>0.105954</td>\n", "    </tr>\n", "    <tr>\n", "      <th>x_bar_integer</th>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "      <td>0.0179036</td>\n", "      <td>0.0251185</td>\n", "      <td>0.0201274</td>\n", "      <td>NaN</td>\n", "      <td>0.0512149</td>\n", "      <td>0.0231931</td>\n", "      <td>0.0250194</td>\n", "    </tr>\n", "    <tr>\n", "      <th>x_box_integer</th>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>x_ege_integer</th>\n", "      <td>0.11634</td>\n", "      <td>0.136102</td>\n", "      <td>0.104482</td>\n", "      <td>0.0715092</td>\n", "      <td>0.100809</td>\n", "      <td>0.0958737</td>\n", "      <td>0.0918505</td>\n", "      <td>0.120958</td>\n", "      <td>0.0651084</td>\n", "      <td>0.139627</td>\n", "    </tr>\n", "    <tr>\n", "      <th>xegvy_integer</th>\n", "      <td>0.070066</td>\n", "      <td>0.0245264</td>\n", "      <td>0.075306</td>\n", "      <td>0.0660088</td>\n", "      <td>0.0618353</td>\n", "      <td>0.0418931</td>\n", "      <td>0.0778766</td>\n", "      <td>0.0708447</td>\n", "      <td>0.0494945</td>\n", "      <td>0.0652668</td>\n", "    </tr>\n", "    <tr>\n", "      <th>xy2br_integer</th>\n", "      <td>0.160418</td>\n", "      <td>0.147171</td>\n", "      <td>0.176543</td>\n", "      <td>0.160391</td>\n", "      <td>0.199033</td>\n", "      <td>0.141797</td>\n", "      <td>0.177919</td>\n", "      <td>0.184016</td>\n", "      <td>0.203256</td>\n", "      <td>0.1528</td>\n", "    </tr>\n", "    <tr>\n", "      <th>xybar_integer</th>\n", "      <td>0.0420876</td>\n", "      <td>0.031269</td>\n", "      <td>0.0285859</td>\n", "      <td>0.0303228</td>\n", "      <td>NaN</td>\n", "      <td>0.0343281</td>\n", "      <td>0.021459</td>\n", "      <td>0.0220206</td>\n", "      <td>0.0414558</td>\n", "      <td>0.0337643</td>\n", "    </tr>\n", "    <tr>\n", "      <th>y2bar_integer</th>\n", "      <td>0.096967</td>\n", "      <td>0.0810997</td>\n", "      <td>0.102401</td>\n", "      <td>0.137525</td>\n", "      <td>0.0561729</td>\n", "      <td>0.104567</td>\n", "      <td>0.113713</td>\n", "      <td>0.0634299</td>\n", "      <td>0.0804799</td>\n", "      <td>0.0338678</td>\n", "    </tr>\n", "    <tr>\n", "      <th>y_bar_integer</th>\n", "      <td>0.0912083</td>\n", "      <td>0.182182</td>\n", "      <td>0.154918</td>\n", "      <td>0.131619</td>\n", "      <td>0.15464</td>\n", "      <td>0.157253</td>\n", "      <td>0.129129</td>\n", "      <td>0.116482</td>\n", "      <td>0.146773</td>\n", "      <td>0.155929</td>\n", "    </tr>\n", "    <tr>\n", "      <th>y_box_integer</th>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "    </tr>\n", "    <tr>\n", "      <th>y_ege_integer</th>\n", "      <td>0.0276356</td>\n", "      <td>0.0416</td>\n", "      <td>0.0370906</td>\n", "      <td>0.064936</td>\n", "      <td>0.0548188</td>\n", "      <td>0.0612151</td>\n", "      <td>0.0249295</td>\n", "      <td>0.0584961</td>\n", "      <td>0.0420701</td>\n", "      <td>0.0560057</td>\n", "    </tr>\n", "    <tr>\n", "      <th>yegvx_integer</th>\n", "      <td>0.0189827</td>\n", "      <td>0.0212195</td>\n", "      <td>0.0300148</td>\n", "      <td>NaN</td>\n", "      <td>0.0248564</td>\n", "      <td>NaN</td>\n", "      <td>0.0163377</td>\n", "      <td>0.0284962</td>\n", "      <td>0.0334997</td>\n", "      <td>0.0388709</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                       0          1          2          3          4  \\\n", "high_integer        None       None       None       None       None   \n", "onpix_integer       None       None       None       None       None   \n", "width_integer   0.115935   0.119533  0.0701563    0.11351  0.0986111   \n", "x2bar_integer   0.112091   0.101648  0.0772696  0.0856666   0.109041   \n", "x2ybr_integer   0.112876  0.0780184  0.0937907  0.0834113    0.07267   \n", "x_bar_integer        NaN        NaN        NaN  0.0179036  0.0251185   \n", "x_box_integer       None       None       None       None       None   \n", "x_ege_integer    0.11634   0.136102   0.104482  0.0715092   0.100809   \n", "xegvy_integer   0.070066  0.0245264   0.075306  0.0660088  0.0618353   \n", "xy2br_integer   0.160418   0.147171   0.176543   0.160391   0.199033   \n", "xybar_integer  0.0420876   0.031269  0.0285859  0.0303228        NaN   \n", "y2bar_integer   0.096967  0.0810997   0.102401   0.137525  0.0561729   \n", "y_bar_integer  0.0912083   0.182182   0.154918   0.131619    0.15464   \n", "y_box_integer       None       None       None       None       None   \n", "y_ege_integer  0.0276356     0.0416  0.0370906   0.064936  0.0548188   \n", "yegvx_integer  0.0189827  0.0212195  0.0300148        NaN  0.0248564   \n", "\n", "                       5          6          7          8          9  \n", "high_integer        None       None       None       None       None  \n", "onpix_integer       None       None       None       None       None  \n", "width_integer    0.10889   0.127594  0.0915672   0.126174  0.0959411  \n", "x2bar_integer   0.082472  0.0967184  0.0767635  0.0827652  0.0602689  \n", "x2ybr_integer   0.106973  0.0785156  0.0812151  0.0756823   0.105954  \n", "x_bar_integer  0.0201274        NaN  0.0512149  0.0231931  0.0250194  \n", "x_box_integer       None       None       None       None       None  \n", "x_ege_integer  0.0958737  0.0918505   0.120958  0.0651084   0.139627  \n", "xegvy_integer  0.0418931  0.0778766  0.0708447  0.0494945  0.0652668  \n", "xy2br_integer   0.141797   0.177919   0.184016   0.203256     0.1528  \n", "xybar_integer  0.0343281   0.021459  0.0220206  0.0414558  0.0337643  \n", "y2bar_integer   0.104567   0.113713  0.0634299  0.0804799  0.0338678  \n", "y_bar_integer   0.157253   0.129129   0.116482   0.146773   0.155929  \n", "y_box_integer       None       None       None       None       None  \n", "y_ege_integer  0.0612151  0.0249295  0.0584961  0.0420701  0.0560057  \n", "yegvx_integer        NaN  0.0163377  0.0284962  0.0334997  0.0388709  "]}}], "source": ["# Respuesta\n", "\n", "features_random_seed = pd.DataFrame(features_random_seed).T\n", "features_random_seed"]}, {"metadata": {}, "source": ["\n", "\n", "Mostramos las variables m\u00e1s importantes. Las podemos tener en diccionario o en lista ordenada."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 20, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 20, "data": {"text/plain": ["width_integer    0.106791\n", "x2bar_integer    0.088470\n", "x2ybr_integer    0.088911\n", "x_bar_integer    0.027096\n", "x_ege_integer    0.104266\n", "xegvy_integer    0.060312\n", "xy2br_integer    0.170334\n", "xybar_integer    0.031699\n", "y2bar_integer    0.087022\n", "y_bar_integer    0.142013\n", "y_ege_integer    0.046880\n", "yegvx_integer    0.026535\n", "dtype: float64"]}}], "source": ["# Respuesta\n", "\n", "feature_importances = features_random_seed.dropna(how='all').mean(axis=1)\n", "feature_importances"]}, {"metadata": {}, "cell_type": "code", "execution_count": 23, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 23, "data": {"text/plain": ["[('xy2br_integer', 0.17033443008368546),\n", " ('y_bar_integer', 0.14201330587864597),\n", " ('width_integer', 0.10679107744754845),\n", " ('x_ege_integer', 0.10426602229681688),\n", " ('x2ybr_integer', 0.08891062630343924),\n", " ('x2bar_integer', 0.0884704983869273),\n", " ('y2bar_integer', 0.08702226475991735),\n", " ('xegvy_integer', 0.06031182687195572),\n", " ('y_ege_integer', 0.046879765726505956),\n", " ('xybar_integer', 0.03169922602840045),\n", " ('x_bar_integer', 0.027096154545888443),\n", " ('yegvx_integer', 0.02653475020862006)]"]}}], "source": ["# Respuesta\n", "\n", "list_of_feature_importance = sorted(zip(feature_importances.index, feature_importances), \n", "                                    key=lambda x: x[1],\n", "                                    reverse=True)\n", "list_of_feature_importance"]}, {"metadata": {}, "source": ["\n", "\n", "Ahora mismo no necesitamos m\u00e1s que la lista sencilla."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 26, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 26, "data": {"text/plain": ["['xy2br_integer',\n", " 'y_bar_integer',\n", " 'width_integer',\n", " 'x_ege_integer',\n", " 'x2ybr_integer',\n", " 'x2bar_integer',\n", " 'y2bar_integer',\n", " 'xegvy_integer',\n", " 'y_ege_integer',\n", " 'xybar_integer',\n", " 'x_bar_integer',\n", " 'yegvx_integer']"]}}], "source": ["# Respuesta\n", "\n", "final_features = [_[0] for _ in list_of_feature_importance]\n", "\n", "final_features"]}, {"metadata": {}, "source": ["\n", "\n", "Hemos visto las variables m\u00e1s importantes, podr\u00edamos intentar usar s\u00f3lo esas para nuestro modelo viendo cu\u00e1l es el resultado de realizar eso. En esta caso, vamos a continuar con todas.\n", "\n", "Estandarizamos los valores y lanzamos un modelo de clasificaci\u00f3n dentro de un Pipeline"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 33, "outputs": [], "source": ["final_features = letters.columns\n", "final_features.remove(\"tag\")\n", "final_features.remove(\"class\")\n", "final_features.remove(\"assembled_features\")"]}, {"metadata": {}, "cell_type": "code", "execution_count": 34, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 34, "data": {"text/plain": ["['x_box_integer',\n", " 'y_box_integer',\n", " 'width_integer',\n", " 'high_integer',\n", " 'onpix_integer',\n", " 'x_bar_integer',\n", " 'y_bar_integer',\n", " 'x2bar_integer',\n", " 'y2bar_integer',\n", " 'xybar_integer',\n", " 'x2ybr_integer',\n", " 'xy2br_integer',\n", " 'x_ege_integer',\n", " 'xegvy_integer',\n", " 'y_ege_integer',\n", " 'yegvx_integer']"]}}], "source": ["final_features"]}, {"metadata": {}, "source": ["\n", "\n", "**Regresi\u00f3n Log\u00edstica** \n", "\n", "Vamos a hacer primero el vector assembler para alimentar este al StandardScaler, y la salida del mismo ser\u00e1 el input para nuestro modelo.\n", "\n", "Esto lo hacemos utilizando un Pipeline como ya vimos anteriormente (haciendo el fit y transform s\u00f3lo en el pipeline)."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 35, "outputs": [{"output_type": "stream", "text": ["+-------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----+---+--------------------+----------------------------+---------------------+--------------------+--------------------+----------+\n", "|x_box_integer|y_box_integer|width_integer|high_integer|onpix_integer|x_bar_integer|y_bar_integer|x2bar_integer|y2bar_integer|xybar_integer|x2ybr_integer|xy2br_integer|x_ege_integer|xegvy_integer|y_ege_integer|yegvx_integer|class|tag|  assembled_features|assembled_important_features|standardized_features|       rawPrediction|         probability|prediction|\n", "+-------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----+---+--------------------+----------------------------+---------------------+--------------------+--------------------+----------+\n", "|            0|            0|            0|           0|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|(16,[5,6,7,8,9,10...|        (16,[5,6,7,8,9,10...| (16,[5,6,7,8,9,10...|[0.44275122293912...|[0.60891439648903...|       0.0|\n", "|            0|            0|            0|           0|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|(16,[5,6,7,8,9,10...|        (16,[5,6,7,8,9,10...| (16,[5,6,7,8,9,10...|[0.44275122293912...|[0.60891439648903...|       0.0|\n", "|            0|            0|            0|           0|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|(16,[5,6,7,8,9,10...|        (16,[5,6,7,8,9,10...| (16,[5,6,7,8,9,10...|[0.44275122293912...|[0.60891439648903...|       0.0|\n", "|            0|            0|            0|           1|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|[0.0,0.0,0.0,1.0,...|        [0.0,0.0,0.0,1.0,...| [0.0,0.0,0.0,0.44...|[0.49429019975274...|[0.62111657171381...|       0.0|\n", "|            0|            0|            0|           1|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|[0.0,0.0,0.0,1.0,...|        [0.0,0.0,0.0,1.0,...| [0.0,0.0,0.0,0.44...|[0.49429019975274...|[0.62111657171381...|       0.0|\n", "+-------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----+---+--------------------+----------------------------+---------------------+--------------------+--------------------+----------+\n", "only showing top 5 rows\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "from pyspark.ml import Pipeline\n", "from pyspark.ml.feature import StandardScaler\n", "from pyspark.ml.classification import LogisticRegression\n", "\n", "vector_assembler = VectorAssembler(inputCols=final_features, outputCol='assembled_important_features')\n", "standard_scaler = StandardScaler(inputCol=vector_assembler.getOutputCol(), outputCol='standardized_features')\n", "log_reg = LogisticRegression(featuresCol=standard_scaler.getOutputCol(), labelCol='tag')\n", "\n", "pipeline_log_reg = Pipeline(stages=[vector_assembler, standard_scaler, log_reg])\n", "\n", "letters_train, letters_test = letters.randomSplit([0.8,0.2], seed=4)\n", "\n", "pipeline_model_log_reg = pipeline_log_reg.fit(letters_train)\n", "\n", "letters_test_log_reg = pipeline_model_log_reg.transform(letters_test)\n", "\n", "letters_test_log_reg.show(5)\n"]}, {"metadata": {}, "source": ["\n", "\n", "**RandomForest**\n", "\n", "Hacemos lo mismo que con la regresi\u00f3n log\u00edstica pero utilizando como modelo el Random Forest."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 37, "outputs": [{"output_type": "stream", "text": ["+-------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----+---+--------------------+----------------------------+---------------------+--------------------+--------------------+----------+\n", "|x_box_integer|y_box_integer|width_integer|high_integer|onpix_integer|x_bar_integer|y_bar_integer|x2bar_integer|y2bar_integer|xybar_integer|x2ybr_integer|xy2br_integer|x_ege_integer|xegvy_integer|y_ege_integer|yegvx_integer|class|tag|  assembled_features|assembled_important_features|standardized_features|       rawPrediction|         probability|prediction|\n", "+-------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----+---+--------------------+----------------------------+---------------------+--------------------+--------------------+----------+\n", "|            0|            0|            0|           0|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|(16,[5,6,7,8,9,10...|        (16,[5,6,7,8,9,10...| (16,[5,6,7,8,9,10...|[5.46116227065897...|[0.27305811353294...|       1.0|\n", "|            0|            0|            0|           0|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|(16,[5,6,7,8,9,10...|        (16,[5,6,7,8,9,10...| (16,[5,6,7,8,9,10...|[5.46116227065897...|[0.27305811353294...|       1.0|\n", "|            0|            0|            0|           0|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|(16,[5,6,7,8,9,10...|        (16,[5,6,7,8,9,10...| (16,[5,6,7,8,9,10...|[5.46116227065897...|[0.27305811353294...|       1.0|\n", "|            0|            0|            0|           1|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|[0.0,0.0,0.0,1.0,...|        [0.0,0.0,0.0,1.0,...| [0.0,0.0,0.0,0.44...|[5.46116227065897...|[0.27305811353294...|       1.0|\n", "|            0|            0|            0|           1|            0|            7|            7|            4|            4|            7|            6|            8|            0|            8|            0|            8|    I|1.0|[0.0,0.0,0.0,1.0,...|        [0.0,0.0,0.0,1.0,...| [0.0,0.0,0.0,0.44...|[5.46116227065897...|[0.27305811353294...|       1.0|\n", "+-------------+-------------+-------------+------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----+---+--------------------+----------------------------+---------------------+--------------------+--------------------+----------+\n", "only showing top 5 rows\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "from pyspark.ml.classification import RandomForestClassifier\n", "\n", "vector_assembler = VectorAssembler(inputCols=final_features, outputCol='assembled_important_features')\n", "standard_scaler = StandardScaler(inputCol=vector_assembler.getOutputCol(), outputCol='standardized_features')\n", "rf = RandomForestClassifier(featuresCol=standard_scaler.getOutputCol(), labelCol='tag')\n", "\n", "pipeline = Pipeline(stages=[vector_assembler, standard_scaler, rf])\n", "\n", "pipeline_model_rf = pipeline.fit(letters_train)\n", "\n", "letters_test_rf = pipeline_model_rf.transform(letters_test)\n", "\n", "letters_test_rf.show(5)"]}, {"metadata": {}, "source": ["\n", "\n", "### Evaluar modelos para decidir cu\u00e1l predice mejor"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 38, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n", "\n", "def calculate_metrics(dataset, predictionCol, labelCol):\n", "    metrics = BinaryClassificationEvaluator(rawPredictionCol=predictionCol, labelCol=labelCol)\n", "    multimetrics = MulticlassClassificationEvaluator(predictionCol=predictionCol, labelCol=labelCol)\n", "\n", "    # In binary case this four metrics will return the same value\n", "    accuracy = multimetrics.evaluate(dataset, {metrics.metricName: \"accuracy\"})\n", "    recall = multimetrics.evaluate(dataset, {metrics.metricName: \"recall\"})\n", "    precision = multimetrics.evaluate(dataset, {metrics.metricName: \"precision\"})\n", "    f1 = multimetrics.evaluate(dataset, {metrics.metricName: \"f1\"})\n", "\n", "    area_under_pr = metrics.evaluate(dataset, {metrics.metricName: \"areaUnderPR\"})\n", "    area_under_roc = metrics.evaluate(dataset, {metrics.metricName: \"areaUnderROC\"})\n", "    \n", "    return {'accuracy': accuracy, \n", "           'recall': recall, \n", "           'precision': precision,\n", "           'f1': f1,\n", "           'area_under_pr': area_under_pr, \n", "           'area_under_roc': area_under_roc}"]}, {"metadata": {}, "source": ["\n", "\n", "### Regresi\u00f3n Log\u00edstica"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 39, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 39, "data": {"text/plain": ["{'accuracy': 0.7391654342039033,\n", " 'area_under_pr': 0.391099414724887,\n", " 'area_under_roc': 0.5407004432932595,\n", " 'f1': 0.7391654342039033,\n", " 'precision': 0.7391654342039033,\n", " 'recall': 0.7391654342039033}"]}}], "source": ["# Respuesta\n", "\n", "calculate_metrics(letters_test_log_reg, 'prediction', 'tag')"]}, {"metadata": {}, "source": ["\n", "\n", "### Random Forest"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 40, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 40, "data": {"text/plain": ["{'accuracy': 0.8216639150823668,\n", " 'area_under_pr': 0.7147989771132053,\n", " 'area_under_roc': 0.6463850974807331,\n", " 'f1': 0.8216639150823668,\n", " 'precision': 0.8216639150823668,\n", " 'recall': 0.8216639150823668}"]}}], "source": ["# Respuesta\n", "\n", "calculate_metrics(letters_test_rf, 'prediction', 'tag')"]}], "nbformat": 4, "nbformat_minor": 2}