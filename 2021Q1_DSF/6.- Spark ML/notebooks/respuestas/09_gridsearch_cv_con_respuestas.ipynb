{"metadata": {"language_info": {"pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "version": "3.5.2"}, "kernelspec": {"display_name": "d1-spark2python3", "language": "python", "name": "spark-python-d1-spark2python3"}, "toc": {"title_cell": "Table of Contents", "skip_h1_title": false, "number_sections": true, "toc_section_display": true, "base_numbering": 1, "toc_window_display": false, "toc_cell": false, "sideBar": true, "title_sidebar": "Contents", "toc_position": {}, "nav_menu": {}}}, "cells": [{"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 5, "outputs": [], "source": ["SANDBOX_NAME = '' # Sandbox Name\n", "DATA_PATH = \"/data/sandboxes/\"+SANDBOX_NAME+\"/data/\""]}, {"metadata": {}, "source": ["\n", "\n", "# Ejemplo de Param Grid\n", "\n", "Para encontrar los mejores hiperapar\u00e1metros para un modelo, se puede definir un conjunto de posibles valores para cada hiperpar\u00e1metro, y crear un programa que entrene modelos con cada combinaci\u00f3n posible de ellos, y almacene el mejor modelo dada una metrica. Adem\u00e1s se puede mejorar junto con la t\u00e9cnica de Validaci\u00f3n Cruzada."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 6, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.sql import SparkSession\n", "from pyspark.sql import functions as F\n", "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n", "from pyspark.ml.classification import RandomForestClassifier\n", "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n", "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n", "\n", "spark = SparkSession.builder.getOrCreate()"]}, {"metadata": {}, "source": ["\n", "\n", "Primer paso, cargar algunos datos de prueba e inspeccionar."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 7, "outputs": [{"output_type": "stream", "text": ["root\n", " |-- rev_mean: double (nullable = true)\n", " |-- mou_mean: double (nullable = true)\n", " |-- totmrc_mean: double (nullable = true)\n", " |-- da_mean: double (nullable = true)\n", " |-- ovrmou_mean: double (nullable = true)\n", " |-- ovrrev_mean: double (nullable = true)\n", " |-- vceovr_mean: double (nullable = true)\n", " |-- datovr_mean: double (nullable = true)\n", " |-- roam_mean: double (nullable = true)\n", " |-- change_mou: double (nullable = true)\n", " |-- change_rev: double (nullable = true)\n", " |-- drop_vce_mean: double (nullable = true)\n", " |-- drop_dat_mean: double (nullable = true)\n", " |-- blck_vce_mean: double (nullable = true)\n", " |-- blck_dat_mean: double (nullable = true)\n", " |-- unan_vce_mean: double (nullable = true)\n", " |-- unan_dat_mean: double (nullable = true)\n", " |-- plcd_vce_mean: double (nullable = true)\n", " |-- plcd_dat_mean: double (nullable = true)\n", " |-- recv_vce_mean: double (nullable = true)\n", " |-- recv_sms_mean: double (nullable = true)\n", " |-- comp_vce_mean: double (nullable = true)\n", " |-- comp_dat_mean: double (nullable = true)\n", " |-- custcare_mean: double (nullable = true)\n", " |-- ccrndmou_mean: double (nullable = true)\n", " |-- cc_mou_mean: double (nullable = true)\n", " |-- inonemin_mean: double (nullable = true)\n", " |-- threeway_mean: double (nullable = true)\n", " |-- mou_cvce_mean: double (nullable = true)\n", " |-- mou_cdat_mean: double (nullable = true)\n", " |-- mou_rvce_mean: double (nullable = true)\n", " |-- owylis_vce_mean: double (nullable = true)\n", " |-- mouowylisv_mean: double (nullable = true)\n", " |-- iwylis_vce_mean: double (nullable = true)\n", " |-- mouiwylisv_mean: double (nullable = true)\n", " |-- peak_vce_mean: double (nullable = true)\n", " |-- peak_dat_mean: double (nullable = true)\n", " |-- mou_peav_mean: double (nullable = true)\n", " |-- mou_pead_mean: double (nullable = true)\n", " |-- opk_vce_mean: double (nullable = true)\n", " |-- opk_dat_mean: double (nullable = true)\n", " |-- mou_opkv_mean: double (nullable = true)\n", " |-- mou_opkd_mean: double (nullable = true)\n", " |-- drop_blk_mean: double (nullable = true)\n", " |-- attempt_mean: double (nullable = true)\n", " |-- complete_mean: double (nullable = true)\n", " |-- callfwdv_mean: double (nullable = true)\n", " |-- callwait_mean: double (nullable = true)\n", " |-- churn: integer (nullable = true)\n", " |-- months: integer (nullable = true)\n", " |-- uniqsubs: integer (nullable = true)\n", " |-- actvsubs: integer (nullable = true)\n", " |-- new_cell: string (nullable = true)\n", " |-- crclscod: string (nullable = true)\n", " |-- asl_flag: string (nullable = true)\n", " |-- totcalls: integer (nullable = true)\n", " |-- totmou: double (nullable = true)\n", " |-- totrev: double (nullable = true)\n", " |-- adjrev: double (nullable = true)\n", " |-- adjmou: double (nullable = true)\n", " |-- adjqty: integer (nullable = true)\n", " |-- avgrev: double (nullable = true)\n", " |-- avgmou: double (nullable = true)\n", " |-- avgqty: double (nullable = true)\n", " |-- avg3mou: integer (nullable = true)\n", " |-- avg3qty: integer (nullable = true)\n", " |-- avg3rev: integer (nullable = true)\n", " |-- avg6mou: integer (nullable = true)\n", " |-- avg6qty: integer (nullable = true)\n", " |-- avg6rev: integer (nullable = true)\n", " |-- prizm_social_one: string (nullable = true)\n", " |-- area: string (nullable = true)\n", " |-- dualband: string (nullable = true)\n", " |-- refurb_new: string (nullable = true)\n", " |-- hnd_price: double (nullable = true)\n", " |-- phones: integer (nullable = true)\n", " |-- models: integer (nullable = true)\n", " |-- hnd_webcap: string (nullable = true)\n", " |-- truck: integer (nullable = true)\n", " |-- rv: integer (nullable = true)\n", " |-- ownrent: string (nullable = true)\n", " |-- lor: integer (nullable = true)\n", " |-- dwlltype: string (nullable = true)\n", " |-- marital: string (nullable = true)\n", " |-- adults: integer (nullable = true)\n", " |-- infobase: string (nullable = true)\n", " |-- income: integer (nullable = true)\n", " |-- numbcars: integer (nullable = true)\n", " |-- hhstatin: string (nullable = true)\n", " |-- dwllsize: string (nullable = true)\n", " |-- forgntvl: integer (nullable = true)\n", " |-- ethnic: string (nullable = true)\n", " |-- kid0_2: string (nullable = true)\n", " |-- kid3_5: string (nullable = true)\n", " |-- kid6_10: string (nullable = true)\n", " |-- kid11_15: string (nullable = true)\n", " |-- kid16_17: string (nullable = true)\n", " |-- creditcd: string (nullable = true)\n", " |-- eqpdays: integer (nullable = true)\n", " |-- customer_id: integer (nullable = true)\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "df = spark.read.csv(DATA_PATH+'data/telecom_customer_churn.csv', sep=',', header=True, inferSchema=True)\n", "\n", "df = df.select([F.col(c).alias(c.lower().replace('\\. ', '_').replace(' ', '_')) for c in df.columns])\n", "\n", "df.printSchema()"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 8, "outputs": [{"output_type": "stream", "text": ["+--------+--------+-----------+-------+-----------+-----------+-----------+-----------+---------+----------+----------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+-------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+-------------+------------+------------+-------------+-------------+-------------+------------+-------------+-------------+-------------+-----+------+--------+--------+--------+--------+--------+--------+-----------+-------+-------+--------+------+------+------+------+-------+-------+-------+-------+-------+-------+----------------+--------------------+--------+----------+-----------+------+------+----------+-----+---+-------+---+--------+-------+------+--------+------+--------+--------+--------+--------+------+------+------+-------+--------+--------+--------+-------+-----------+\n", "|rev_mean|mou_mean|totmrc_mean|da_mean|ovrmou_mean|ovrrev_mean|vceovr_mean|datovr_mean|roam_mean|change_mou|change_rev|drop_vce_mean|drop_dat_mean|blck_vce_mean|blck_dat_mean|unan_vce_mean|unan_dat_mean|plcd_vce_mean|plcd_dat_mean|recv_vce_mean|recv_sms_mean|comp_vce_mean|comp_dat_mean|custcare_mean|ccrndmou_mean|cc_mou_mean|inonemin_mean|threeway_mean|mou_cvce_mean|mou_cdat_mean|mou_rvce_mean|owylis_vce_mean|mouowylisv_mean|iwylis_vce_mean|mouiwylisv_mean|peak_vce_mean|peak_dat_mean|mou_peav_mean|mou_pead_mean|opk_vce_mean|opk_dat_mean|mou_opkv_mean|mou_opkd_mean|drop_blk_mean|attempt_mean|complete_mean|callfwdv_mean|callwait_mean|churn|months|uniqsubs|actvsubs|new_cell|crclscod|asl_flag|totcalls|     totmou| totrev| adjrev|  adjmou|adjqty|avgrev|avgmou|avgqty|avg3mou|avg3qty|avg3rev|avg6mou|avg6qty|avg6rev|prizm_social_one|                area|dualband|refurb_new|  hnd_price|phones|models|hnd_webcap|truck| rv|ownrent|lor|dwlltype|marital|adults|infobase|income|numbcars|hhstatin|dwllsize|forgntvl|ethnic|kid0_2|kid3_5|kid6_10|kid11_15|kid16_17|creditcd|eqpdays|customer_id|\n", "+--------+--------+-----------+-------+-----------+-----------+-----------+-----------+---------+----------+----------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+-------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+-------------+------------+------------+-------------+-------------+-------------+------------+-------------+-------------+-------------+-----+------+--------+--------+--------+--------+--------+--------+-----------+-------+-------+--------+------+------+------+------+-------+-------+-------+-------+-------+-------+----------------+--------------------+--------+----------+-----------+------+------+----------+-----+---+-------+---+--------+-------+------+--------+------+--------+--------+--------+--------+------+------+------+-------+--------+--------+--------+-------+-----------+\n", "| 23.9975|  219.25|       22.5| 0.2475|        0.0|        0.0|        0.0|        0.0|      0.0|   -157.25|  -18.9975|  0.666666667|          0.0|  0.666666667|          0.0|  6.333333333|          0.0|  52.33333333|          0.0|  42.33333333|          0.0|         45.0|          0.0|          0.0|          0.0|        0.0|         18.0|          0.0|  90.64333333|          0.0|  97.17666667|            0.0|            0.0|            0.0|            0.0|         58.0|          0.0|        132.6|          0.0|        24.0|         0.0|        55.22|          0.0|  1.333333333| 52.33333333|         45.0|          0.0|  0.333333333|    1|    61|       2|       1|       U|       A|       N|    1652|     4228.0|1504.62|1453.44|  4085.0|  1602| 29.66| 83.37| 32.69|    272|    116|     30|    322|    136|     38|               S|NORTHWEST/ROCKY M...|       Y|         N|149.9899902|     2|     2|      WCMB|    0|  0|      O| 15|       S|      S|     1|       M|     4|       3|       C|       A|       0|     N|     U|     U|      U|       U|       U|       Y|    361|    1000001|\n", "| 57.4925|  482.75|     37.425| 0.2475|      22.75|        9.1|        9.1|        0.0|      0.0|    532.25|   50.9875|  8.333333333|          0.0|          1.0|          0.0|  61.33333333|          0.0|  263.3333333|          0.0|         69.0|          0.0|  193.3333333|          0.0|  1.666666667|  6.333333333|5.463333333|         53.0|  0.333333333|  189.3966667|          0.0|        55.28|    46.33333333|    24.21666667|    6.333333333|    3.696666667|  83.66666667|          0.0|  75.33333333|          0.0|       157.0|         0.0|  169.3433333|          0.0|  9.333333333| 263.3333333|  193.3333333|          0.0|  5.666666667|    0|    56|       1|       1|       N|      EA|       N|   14654|    26400.0|2851.68|2833.88| 26367.0| 14624| 51.53| 479.4|265.89|    305|    158|     40|    477|    275|     48|               U|        CHICAGO AREA|       N|         N|       null|     7|     6|        WC|    1|  1|   null|  1|       S|      S|     1|       M|     5|       1|       C|       A|       0|     Z|     U|     U|      U|       U|       U|       Y|    240|    1000002|\n", "|   16.99|   10.25|      16.99|    0.0|        0.0|        0.0|        0.0|        0.0|      0.0|     -4.25|       0.0|  0.333333333|          0.0|          0.0|          0.0|  2.666666667|          0.0|          9.0|          0.0|  0.333333333|          0.0|          6.0|          0.0|          0.0|          0.0|        0.0|  0.333333333|          0.0|  5.426666667|          0.0|          0.0|            0.0|            0.0|            0.0|            0.0|          5.0|          0.0|  5.193333333|          0.0|         1.0|         0.0|  0.233333333|          0.0|  0.333333333|         9.0|          6.0|          0.0|          0.0|    1|    58|       1|       1|       Y|       C|       N|    7903|24385.05333|2155.91|1934.47|24303.05|  7888| 34.54|433.98|140.86|     12|      7|     17|     11|      6|     17|               S|    GREAT LAKES AREA|       N|         N|29.98999023|     2|     1|        NA|    0|  0|      O|  7|       S|      M|     2|       M|     5|       2|       C|       A|       0|     N|     U|     Y|      U|       U|       U|       Y|   1504|    1000003|\n", "|    38.0|     7.5|       38.0|    0.0|        0.0|        0.0|        0.0|        0.0|      0.0|      -1.5|       0.0|          0.0|          0.0|          0.0|          0.0|          0.0|          0.0|  3.666666667|          0.0|  1.333333333|          0.0|  3.666666667|          0.0|          0.0|          0.0|        0.0|  1.333333333|          0.0|         8.41|          0.0|  0.413333333|    0.333333333|    0.256666667|            0.0|            0.0|  1.333333333|          0.0|         3.38|          0.0| 3.666666667|         0.0|         5.45|          0.0|          0.0| 3.666666667|  3.666666667|          0.0|          0.0|    0|    60|       1|       1|       Y|       B|       N|    1502|     3065.0| 2000.9|1941.81|  3035.0|  1479| 40.45| 63.23| 30.81|      8|      3|     38|     50|     25|     40|               T|        CHICAGO AREA|       N|         N|29.98999023|     1|     1|        NA|    0|  0|   null|  6|       M|      M|     4|       M|     6|       1|       C|       D|       0|     U|     Y|     U|      U|       U|       U|       Y|   1812|    1000004|\n", "|   55.23|   570.5|      71.98|    0.0|        0.0|        0.0|        0.0|        0.0|      0.0|      38.5|       0.0|  9.666666667|          0.0|  0.666666667|          0.0|         77.0|          0.0|  222.3333333|          0.0|  94.66666667|          0.0|        137.0|          0.0|  8.666666667|         15.0|11.07666667|         66.0|          0.0|  285.2333333|          0.0|       106.33|    14.66666667|    10.81666667|    0.666666667|    0.366666667|  97.33333333|          0.0|  173.4766667|          0.0| 90.33333333|         0.0|  218.0866667|          0.0|  10.33333333| 222.3333333|        137.0|          0.0|          0.0|    0|    57|       1|       1|       Y|       A|       N|    4485|    14028.0|2181.12|2166.48| 13965.0|  4452| 38.69|249.38|  79.5|    558|    191|     55|    586|    196|     80|               U|    NEW ENGLAND AREA|       Y|         N|149.9899902|     6|     4|      WCMB|    0|  0|      R|  5|       M|      S|     1|       M|     6|       1|       C|       O|       0|     I|     U|     U|      U|       U|       U|       Y|    434|    1000005|\n", "+--------+--------+-----------+-------+-----------+-----------+-----------+-----------+---------+----------+----------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+-------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+-------------+------------+------------+-------------+-------------+-------------+------------+-------------+-------------+-------------+-----+------+--------+--------+--------+--------+--------+--------+-----------+-------+-------+--------+------+------+------+------+-------+-------+-------+-------+-------+-------+----------------+--------------------+--------+----------+-----------+------+------+----------+-----+---+-------+---+--------+-------+------+--------+------+--------+--------+--------+--------+------+------+------+-------+--------+--------+--------+-------+-----------+\n", "only showing top 5 rows\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "df.show(5)"]}, {"metadata": {}, "source": ["\n", "\n", "Busquemos valores nulos en todas las columnas y descartemos filas que tengan nulos en ellas. Ya vimos anteriormente c\u00f3mo trabajar con valores nulos."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 9, "outputs": [{"output_type": "stream", "text": ["Looking for nulls at rev_mean\n", "There are null values in the column rev_mean\n", "Looking for nulls at mou_mean\n", "-> None null found.\n", "Looking for nulls at totmrc_mean\n", "-> None null found.\n", "Looking for nulls at da_mean\n", "-> None null found.\n", "Looking for nulls at ovrmou_mean\n", "-> None null found.\n", "Looking for nulls at ovrrev_mean\n", "-> None null found.\n", "Looking for nulls at vceovr_mean\n", "-> None null found.\n", "Looking for nulls at datovr_mean\n", "-> None null found.\n", "Looking for nulls at roam_mean\n", "-> None null found.\n", "Looking for nulls at change_mou\n", "There are null values in the column change_mou\n", "Looking for nulls at change_rev\n", "-> None null found.\n", "Looking for nulls at drop_vce_mean\n", "-> None null found.\n", "Looking for nulls at drop_dat_mean\n", "-> None null found.\n", "Looking for nulls at blck_vce_mean\n", "-> None null found.\n", "Looking for nulls at blck_dat_mean\n", "-> None null found.\n", "Looking for nulls at unan_vce_mean\n", "-> None null found.\n", "Looking for nulls at unan_dat_mean\n", "-> None null found.\n", "Looking for nulls at plcd_vce_mean\n", "-> None null found.\n", "Looking for nulls at plcd_dat_mean\n", "-> None null found.\n", "Looking for nulls at recv_vce_mean\n", "-> None null found.\n", "Looking for nulls at recv_sms_mean\n", "-> None null found.\n", "Looking for nulls at comp_vce_mean\n", "-> None null found.\n", "Looking for nulls at comp_dat_mean\n", "-> None null found.\n", "Looking for nulls at custcare_mean\n", "-> None null found.\n", "Looking for nulls at ccrndmou_mean\n", "-> None null found.\n", "Looking for nulls at cc_mou_mean\n", "-> None null found.\n", "Looking for nulls at inonemin_mean\n", "-> None null found.\n", "Looking for nulls at threeway_mean\n", "-> None null found.\n", "Looking for nulls at mou_cvce_mean\n", "-> None null found.\n", "Looking for nulls at mou_cdat_mean\n", "-> None null found.\n", "Looking for nulls at mou_rvce_mean\n", "-> None null found.\n", "Looking for nulls at owylis_vce_mean\n", "-> None null found.\n", "Looking for nulls at mouowylisv_mean\n", "-> None null found.\n", "Looking for nulls at iwylis_vce_mean\n", "-> None null found.\n", "Looking for nulls at mouiwylisv_mean\n", "-> None null found.\n", "Looking for nulls at peak_vce_mean\n", "-> None null found.\n", "Looking for nulls at peak_dat_mean\n", "-> None null found.\n", "Looking for nulls at mou_peav_mean\n", "-> None null found.\n", "Looking for nulls at mou_pead_mean\n", "-> None null found.\n", "Looking for nulls at opk_vce_mean\n", "-> None null found.\n", "Looking for nulls at opk_dat_mean\n", "-> None null found.\n", "Looking for nulls at mou_opkv_mean\n", "-> None null found.\n", "Looking for nulls at mou_opkd_mean\n", "-> None null found.\n", "Looking for nulls at drop_blk_mean\n", "-> None null found.\n", "Looking for nulls at attempt_mean\n", "-> None null found.\n", "Looking for nulls at complete_mean\n", "-> None null found.\n", "Looking for nulls at callfwdv_mean\n", "-> None null found.\n", "Looking for nulls at callwait_mean\n", "-> None null found.\n", "Looking for nulls at churn\n", "-> None null found.\n", "Looking for nulls at months\n", "-> None null found.\n", "Looking for nulls at uniqsubs\n", "-> None null found.\n", "Looking for nulls at actvsubs\n", "-> None null found.\n", "Looking for nulls at new_cell\n", "-> None null found.\n", "Looking for nulls at crclscod\n", "-> None null found.\n", "Looking for nulls at asl_flag\n", "-> None null found.\n", "Looking for nulls at totcalls\n", "-> None null found.\n", "Looking for nulls at totmou\n", "-> None null found.\n", "Looking for nulls at totrev\n", "-> None null found.\n", "Looking for nulls at adjrev\n", "-> None null found.\n", "Looking for nulls at adjmou\n", "-> None null found.\n", "Looking for nulls at adjqty\n", "-> None null found.\n", "Looking for nulls at avgrev\n", "-> None null found.\n", "Looking for nulls at avgmou\n", "-> None null found.\n", "Looking for nulls at avgqty\n", "-> None null found.\n", "Looking for nulls at avg3mou\n", "-> None null found.\n", "Looking for nulls at avg3qty\n", "-> None null found.\n", "Looking for nulls at avg3rev\n", "-> None null found.\n", "Looking for nulls at avg6mou\n", "There are null values in the column avg6mou\n", "Looking for nulls at avg6qty\n", "-> None null found.\n", "Looking for nulls at avg6rev\n", "-> None null found.\n", "Looking for nulls at prizm_social_one\n", "There are null values in the column prizm_social_one\n", "Looking for nulls at area\n", "There are null values in the column area\n", "Looking for nulls at dualband\n", "There are null values in the column dualband\n", "Looking for nulls at refurb_new\n", "-> None null found.\n", "Looking for nulls at hnd_price\n", "There are null values in the column hnd_price\n", "Looking for nulls at phones\n", "-> None null found.\n", "Looking for nulls at models\n", "-> None null found.\n", "Looking for nulls at hnd_webcap\n", "-> None null found.\n", "Looking for nulls at truck\n", "There are null values in the column truck\n", "Looking for nulls at rv\n", "-> None null found.\n", "Looking for nulls at ownrent\n", "There are null values in the column ownrent\n", "Looking for nulls at lor\n", "There are null values in the column lor\n", "Looking for nulls at dwlltype\n", "There are null values in the column dwlltype\n", "Looking for nulls at marital\n", "-> None null found.\n", "Looking for nulls at adults\n", "There are null values in the column adults\n", "Looking for nulls at infobase\n", "-> None null found.\n", "Looking for nulls at income\n", "There are null values in the column income\n", "Looking for nulls at numbcars\n", "There are null values in the column numbcars\n", "Looking for nulls at hhstatin\n", "There are null values in the column hhstatin\n", "Looking for nulls at dwllsize\n", "There are null values in the column dwllsize\n", "Looking for nulls at forgntvl\n", "-> None null found.\n", "Looking for nulls at ethnic\n", "-> None null found.\n", "Looking for nulls at kid0_2\n", "-> None null found.\n", "Looking for nulls at kid3_5\n", "-> None null found.\n", "Looking for nulls at kid6_10\n", "-> None null found.\n", "Looking for nulls at kid11_15\n", "-> None null found.\n", "Looking for nulls at kid16_17\n", "-> None null found.\n", "Looking for nulls at creditcd\n", "-> None null found.\n", "Looking for nulls at eqpdays\n", "-> None null found.\n", "Looking for nulls at customer_id\n", "-> None null found.\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "for column in df.columns:\n", "    print(\"Looking for nulls at \" +column)\n", "    num_nulls = df.where(F.col(column).isNull()).count()\n", "    if  num_nulls != 0:\n", "        print(\"There are null values in the column {}\".format(column))\n", "        df = df.where(F.col(column).isNotNull())\n", "        if num_nulls == 0:\n", "            print(\"The column {} is free from null values\".format(column))\n", "    else:\n", "        print(\"-> None null found.\")"]}, {"metadata": {}, "source": ["\n", "\n", "Tras limpiar el dataset de nulos, podemos continuar preparando las variables y entrenando un modelo.\n", "Para mantenerlo sencillo, apuntaremos las columnas binarias para evitar aplicarles onehot.\n", "\n", "- Aplicamos el string indexer a todas las columnas tipo string (estamos asumiendo aqu\u00ed que todas las columnas tipo string son categ\u00f3ricas)\n", "- Aplicamos one hot encoder a todas las variables string no binarias\n", "- Tras el string indexer Y el one hot encoder en las variables no binarias, removemos la columna resultado del string indexer para quedarnos s\u00f3lo con la salida del one hot encoder. Y le cambiamos el nombre a la salida del one hot encoder a *_encoded*. As\u00ed s\u00f3lo tendremos una variable *_encoded* para cada variable transformada en lugar de tener en el dataset el resultado del string indexer Y el del one hot encoder."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 10, "outputs": [], "source": ["# Respuesta\n", "\n", "binary_columns = ['asl_flag', 'refurb_new', 'ownrent',  'dwlltype', 'kid0_2', 'kid3_5',  'kid6_10',  'kid11_15',  'kid16_17', 'creditcd'] \n", "\n", "original_numerical_columns = [item[0] for item in df.dtypes if item[1] in ['double', 'float', 'int'] and \n", "                             item[0]!='churn']\n", "\n", "string_columns = [item[0] for item in df.dtypes if item[1]=='string']    "]}, {"metadata": {}, "cell_type": "code", "execution_count": 11, "outputs": [{"output_type": "stream", "text": ["new_cell\n", "crclscod\n", "asl_flag\n", "prizm_social_one\n", "area\n", "dualband\n", "refurb_new\n", "hnd_webcap\n", "ownrent\n", "dwlltype\n", "marital\n", "infobase\n", "hhstatin\n", "dwllsize\n", "ethnic\n", "kid0_2\n", "kid3_5\n", "kid6_10\n", "kid11_15\n", "kid16_17\n", "creditcd\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "# making a copy of our dataset\n", "df_many_steps = df\n", "\n", "for col in string_columns:\n", "    print(col)\n", "    string_indexer = StringIndexer(inputCol=col, outputCol=col+\"_encoded\")\n", "    string_indexer_model = string_indexer.fit(df_many_steps)\n", "    df_many_steps = string_indexer_model.transform(df_many_steps)\n", "    \n", "    if col not in binary_columns:\n", "        onehotencoder = OneHotEncoder(dropLast=False, inputCol= string_indexer.getOutputCol(), outputCol=col+\"_encoded_tmp\")\n", "        \n", "        df_many_steps = onehotencoder.transform(df_many_steps)\n", "        df_many_steps = df_many_steps.drop(string_indexer.getOutputCol())\n", "        df_many_steps = df_many_steps.withColumnRenamed(onehotencoder.getOutputCol(),string_indexer.getOutputCol())\n", "    "]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 12, "outputs": [{"output_type": "stream", "text": ["+--------+--------+-----------+-------+-----------+-----------+-----------+-----------+---------+----------+----------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+-------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+-------------+------------+------------+-------------+-------------+-------------+------------+-------------+-------------+-------------+-----+------+--------+--------+--------+--------+--------+--------+-----------+-------+-------+--------+------+------+-------+------+-------+-------+-------+-------+-------+-------+----------------+--------------------+--------+----------+-----------+------+------+----------+-----+---+-------+---+--------+-------+------+--------+------+--------+--------+--------+--------+------+------+------+-------+--------+--------+--------+-------+-----------+----------------+----------------+----------------+------------------------+---------------+----------------+------------------+------------------+---------------+----------------+---------------+----------------+----------------+----------------+--------------+--------------+--------------+---------------+----------------+----------------+----------------+\n", "|rev_mean|mou_mean|totmrc_mean|da_mean|ovrmou_mean|ovrrev_mean|vceovr_mean|datovr_mean|roam_mean|change_mou|change_rev|drop_vce_mean|drop_dat_mean|blck_vce_mean|blck_dat_mean|unan_vce_mean|unan_dat_mean|plcd_vce_mean|plcd_dat_mean|recv_vce_mean|recv_sms_mean|comp_vce_mean|comp_dat_mean|custcare_mean|ccrndmou_mean|cc_mou_mean|inonemin_mean|threeway_mean|mou_cvce_mean|mou_cdat_mean|mou_rvce_mean|owylis_vce_mean|mouowylisv_mean|iwylis_vce_mean|mouiwylisv_mean|peak_vce_mean|peak_dat_mean|mou_peav_mean|mou_pead_mean|opk_vce_mean|opk_dat_mean|mou_opkv_mean|mou_opkd_mean|drop_blk_mean|attempt_mean|complete_mean|callfwdv_mean|callwait_mean|churn|months|uniqsubs|actvsubs|new_cell|crclscod|asl_flag|totcalls|     totmou| totrev| adjrev|  adjmou|adjqty|avgrev| avgmou|avgqty|avg3mou|avg3qty|avg3rev|avg6mou|avg6qty|avg6rev|prizm_social_one|                area|dualband|refurb_new|  hnd_price|phones|models|hnd_webcap|truck| rv|ownrent|lor|dwlltype|marital|adults|infobase|income|numbcars|hhstatin|dwllsize|forgntvl|ethnic|kid0_2|kid3_5|kid6_10|kid11_15|kid16_17|creditcd|eqpdays|customer_id|new_cell_encoded|crclscod_encoded|asl_flag_encoded|prizm_social_one_encoded|   area_encoded|dualband_encoded|refurb_new_encoded|hnd_webcap_encoded|ownrent_encoded|dwlltype_encoded|marital_encoded|infobase_encoded|hhstatin_encoded|dwllsize_encoded|ethnic_encoded|kid0_2_encoded|kid3_5_encoded|kid6_10_encoded|kid11_15_encoded|kid16_17_encoded|creditcd_encoded|\n", "+--------+--------+-----------+-------+-----------+-----------+-----------+-----------+---------+----------+----------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+-------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+-------------+------------+------------+-------------+-------------+-------------+------------+-------------+-------------+-------------+-----+------+--------+--------+--------+--------+--------+--------+-----------+-------+-------+--------+------+------+-------+------+-------+-------+-------+-------+-------+-------+----------------+--------------------+--------+----------+-----------+------+------+----------+-----+---+-------+---+--------+-------+------+--------+------+--------+--------+--------+--------+------+------+------+-------+--------+--------+--------+-------+-----------+----------------+----------------+----------------+------------------------+---------------+----------------+------------------+------------------+---------------+----------------+---------------+----------------+----------------+----------------+--------------+--------------+--------------+---------------+----------------+----------------+----------------+\n", "| 23.9975|  219.25|       22.5| 0.2475|        0.0|        0.0|        0.0|        0.0|      0.0|   -157.25|  -18.9975|  0.666666667|          0.0|  0.666666667|          0.0|  6.333333333|          0.0|  52.33333333|          0.0|  42.33333333|          0.0|         45.0|          0.0|          0.0|          0.0|        0.0|         18.0|          0.0|  90.64333333|          0.0|  97.17666667|            0.0|            0.0|            0.0|            0.0|         58.0|          0.0|        132.6|          0.0|        24.0|         0.0|        55.22|          0.0|  1.333333333| 52.33333333|         45.0|          0.0|  0.333333333|    1|    61|       2|       1|       U|       A|       N|    1652|     4228.0|1504.62|1453.44|  4085.0|  1602| 29.66|  83.37| 32.69|    272|    116|     30|    322|    136|     38|               S|NORTHWEST/ROCKY M...|       Y|         N|149.9899902|     2|     2|      WCMB|    0|  0|      O| 15|       S|      S|     1|       M|     4|       3|       C|       A|       0|     N|     U|     U|      U|       U|       U|       Y|    361|    1000001|   (3,[0],[1.0])|  (44,[1],[1.0])|             0.0|           (5,[0],[1.0])|(19,[15],[1.0])|   (3,[0],[1.0])|               0.0|     (3,[0],[1.0])|            0.0|             0.0|  (5,[1],[1.0])|   (1,[0],[1.0])|   (6,[0],[1.0])|  (15,[0],[1.0])|(16,[0],[1.0])|           0.0|           0.0|            0.0|             0.0|             0.0|             0.0|\n", "|   16.99|   10.25|      16.99|    0.0|        0.0|        0.0|        0.0|        0.0|      0.0|     -4.25|       0.0|  0.333333333|          0.0|          0.0|          0.0|  2.666666667|          0.0|          9.0|          0.0|  0.333333333|          0.0|          6.0|          0.0|          0.0|          0.0|        0.0|  0.333333333|          0.0|  5.426666667|          0.0|          0.0|            0.0|            0.0|            0.0|            0.0|          5.0|          0.0|  5.193333333|          0.0|         1.0|         0.0|  0.233333333|          0.0|  0.333333333|         9.0|          6.0|          0.0|          0.0|    1|    58|       1|       1|       Y|       C|       N|    7903|24385.05333|2155.91|1934.47|24303.05|  7888| 34.54| 433.98|140.86|     12|      7|     17|     11|      6|     17|               S|    GREAT LAKES AREA|       N|         N|29.98999023|     2|     1|        NA|    0|  0|      O|  7|       S|      M|     2|       M|     5|       2|       C|       A|       0|     N|     U|     Y|      U|       U|       U|       Y|   1504|    1000003|   (3,[1],[1.0])|  (44,[7],[1.0])|             0.0|           (5,[0],[1.0])| (19,[3],[1.0])|   (3,[1],[1.0])|               0.0|     (3,[2],[1.0])|            0.0|             0.0|  (5,[0],[1.0])|   (1,[0],[1.0])|   (6,[0],[1.0])|  (15,[0],[1.0])|(16,[0],[1.0])|           0.0|           1.0|            0.0|             0.0|             0.0|             0.0|\n", "|   55.23|   570.5|      71.98|    0.0|        0.0|        0.0|        0.0|        0.0|      0.0|      38.5|       0.0|  9.666666667|          0.0|  0.666666667|          0.0|         77.0|          0.0|  222.3333333|          0.0|  94.66666667|          0.0|        137.0|          0.0|  8.666666667|         15.0|11.07666667|         66.0|          0.0|  285.2333333|          0.0|       106.33|    14.66666667|    10.81666667|    0.666666667|    0.366666667|  97.33333333|          0.0|  173.4766667|          0.0| 90.33333333|         0.0|  218.0866667|          0.0|  10.33333333| 222.3333333|        137.0|          0.0|          0.0|    0|    57|       1|       1|       Y|       A|       N|    4485|    14028.0|2181.12|2166.48| 13965.0|  4452| 38.69| 249.38|  79.5|    558|    191|     55|    586|    196|     80|               U|    NEW ENGLAND AREA|       Y|         N|149.9899902|     6|     4|      WCMB|    0|  0|      R|  5|       M|      S|     1|       M|     6|       1|       C|       O|       0|     I|     U|     U|      U|       U|       U|       Y|    434|    1000005|   (3,[1],[1.0])|  (44,[1],[1.0])|             0.0|           (5,[2],[1.0])|(19,[11],[1.0])|   (3,[0],[1.0])|               0.0|     (3,[0],[1.0])|            1.0|             1.0|  (5,[1],[1.0])|   (1,[0],[1.0])|   (6,[0],[1.0])|  (15,[4],[1.0])|(16,[5],[1.0])|           0.0|           0.0|            0.0|             0.0|             0.0|             0.0|\n", "| 31.6625|    25.5|      29.99| 0.2475|        0.0|        0.0|        0.0|        0.0|      0.0|      59.5|    4.0275|          0.0|          0.0|          1.0|          0.0|  2.333333333|          0.0|  6.666666667|          0.0|          0.0|          0.0|  3.333333333|          0.0|          0.0|          0.0|        0.0|          0.0|          0.0|          3.8|          0.0|          0.0|            0.0|            0.0|            0.0|            0.0|  1.666666667|          0.0|  1.866666667|          0.0| 1.666666667|         0.0|  1.933333333|          0.0|          1.0| 6.666666667|  3.333333333|          0.0|          0.0|    0|    57|       2|       2|       N|       A|       N|     391|      994.0|1458.42|1457.84|   976.0|   377| 26.51|  17.75|  6.85|      6|      3|     30|     54|      7|     34|               C|         DALLAS AREA|       Y|         N|79.98999023|     2|     2|      WCMB|    0|  0|      O|  8|       S|      M|     2|       M|     9|       2|       I|       A|       1|     N|     U|     U|      U|       U|       U|       Y|    601|    1000010|   (3,[2],[1.0])|  (44,[1],[1.0])|             0.0|           (5,[3],[1.0])| (19,[2],[1.0])|   (3,[0],[1.0])|               0.0|     (3,[0],[1.0])|            0.0|             0.0|  (5,[0],[1.0])|   (1,[0],[1.0])|   (6,[1],[1.0])|  (15,[0],[1.0])|(16,[0],[1.0])|           0.0|           0.0|            0.0|             0.0|             0.0|             0.0|\n", "| 212.515|  1971.5|      84.99| 2.2275|      249.5|       99.8|       99.8|        0.0|  35.4975|    -200.5|  -106.765|          9.0|          0.0|          0.0|          0.0|  43.66666667|          0.0|  344.6666667|          0.0|  271.3333333|          0.0|        296.0|          0.0|  0.333333333|  3.333333333|3.316666667|  126.3333333|          0.0|  581.2966667|          0.0|       718.07|    49.33333333|    35.16333333|    4.666666667|    9.263333333|  351.6666667|          0.0|  864.1733333|          0.0| 128.6666667|         0.0|  435.1933333|          0.0|          9.0| 344.6666667|        296.0|          0.0|          1.0|    0|    59|       5|       1|       Y|       C|       N|   33184|69161.08333|6616.72| 6572.7|69104.08| 33139|115.31|1212.35|581.39|   2038|    637|    248|   1817|    576|    182|               S|NORTHWEST/ROCKY M...|       Y|         N|149.9899902|    10|     6|      WCMB|    0|  0|      O| 11|       S|      S|     3|       M|     3|       2|       I|       A|       0|     N|     U|     U|      Y|       U|       U|       Y|    199|    1000015|   (3,[1],[1.0])|  (44,[7],[1.0])|             0.0|           (5,[0],[1.0])|(19,[15],[1.0])|   (3,[0],[1.0])|               0.0|     (3,[0],[1.0])|            0.0|             0.0|  (5,[1],[1.0])|   (1,[0],[1.0])|   (6,[1],[1.0])|  (15,[0],[1.0])|(16,[0],[1.0])|           0.0|           0.0|            1.0|             0.0|             0.0|             0.0|\n", "+--------+--------+-----------+-------+-----------+-----------+-----------+-----------+---------+----------+----------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-----------+-------------+-------------+-------------+-------------+-------------+---------------+---------------+---------------+---------------+-------------+-------------+-------------+-------------+------------+------------+-------------+-------------+-------------+------------+-------------+-------------+-------------+-----+------+--------+--------+--------+--------+--------+--------+-----------+-------+-------+--------+------+------+-------+------+-------+-------+-------+-------+-------+-------+----------------+--------------------+--------+----------+-----------+------+------+----------+-----+---+-------+---+--------+-------+------+--------+------+--------+--------+--------+--------+------+------+------+-------+--------+--------+--------+-------+-----------+----------------+----------------+----------------+------------------------+---------------+----------------+------------------+------------------+---------------+----------------+---------------+----------------+----------------+----------------+--------------+--------------+--------------+---------------+----------------+----------------+----------------+\n", "only showing top 5 rows\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "df_many_steps.show(5)"]}, {"metadata": {}, "source": ["\n", "\n", "Listamos columnas de entrenamiento y seleccionamos columna de target"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 13, "outputs": [], "source": ["# Respuesta\n", "\n", "target_column = \"churn\"\n", "numeric_columns = [element[0] for element in df_many_steps.dtypes if element[1] != 'string' and element[0]!='customer_id']\n", "columns_for_model = [c for c in numeric_columns if c!=target_column]"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 14, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 14, "data": {"text/plain": ["['rev_mean',\n", " 'mou_mean',\n", " 'totmrc_mean',\n", " 'da_mean',\n", " 'ovrmou_mean',\n", " 'ovrrev_mean',\n", " 'vceovr_mean',\n", " 'datovr_mean',\n", " 'roam_mean',\n", " 'change_mou',\n", " 'change_rev',\n", " 'drop_vce_mean',\n", " 'drop_dat_mean',\n", " 'blck_vce_mean',\n", " 'blck_dat_mean',\n", " 'unan_vce_mean',\n", " 'unan_dat_mean',\n", " 'plcd_vce_mean',\n", " 'plcd_dat_mean',\n", " 'recv_vce_mean',\n", " 'recv_sms_mean',\n", " 'comp_vce_mean',\n", " 'comp_dat_mean',\n", " 'custcare_mean',\n", " 'ccrndmou_mean',\n", " 'cc_mou_mean',\n", " 'inonemin_mean',\n", " 'threeway_mean',\n", " 'mou_cvce_mean',\n", " 'mou_cdat_mean',\n", " 'mou_rvce_mean',\n", " 'owylis_vce_mean',\n", " 'mouowylisv_mean',\n", " 'iwylis_vce_mean',\n", " 'mouiwylisv_mean',\n", " 'peak_vce_mean',\n", " 'peak_dat_mean',\n", " 'mou_peav_mean',\n", " 'mou_pead_mean',\n", " 'opk_vce_mean',\n", " 'opk_dat_mean',\n", " 'mou_opkv_mean',\n", " 'mou_opkd_mean',\n", " 'drop_blk_mean',\n", " 'attempt_mean',\n", " 'complete_mean',\n", " 'callfwdv_mean',\n", " 'callwait_mean',\n", " 'months',\n", " 'uniqsubs',\n", " 'actvsubs',\n", " 'totcalls',\n", " 'totmou',\n", " 'totrev',\n", " 'adjrev',\n", " 'adjmou',\n", " 'adjqty',\n", " 'avgrev',\n", " 'avgmou',\n", " 'avgqty',\n", " 'avg3mou',\n", " 'avg3qty',\n", " 'avg3rev',\n", " 'avg6mou',\n", " 'avg6qty',\n", " 'avg6rev',\n", " 'hnd_price',\n", " 'phones',\n", " 'models',\n", " 'truck',\n", " 'rv',\n", " 'lor',\n", " 'adults',\n", " 'income',\n", " 'numbcars',\n", " 'forgntvl',\n", " 'eqpdays',\n", " 'new_cell_encoded',\n", " 'crclscod_encoded',\n", " 'asl_flag_encoded',\n", " 'prizm_social_one_encoded',\n", " 'area_encoded',\n", " 'dualband_encoded',\n", " 'refurb_new_encoded',\n", " 'hnd_webcap_encoded',\n", " 'ownrent_encoded',\n", " 'dwlltype_encoded',\n", " 'marital_encoded',\n", " 'infobase_encoded',\n", " 'hhstatin_encoded',\n", " 'dwllsize_encoded',\n", " 'ethnic_encoded',\n", " 'kid0_2_encoded',\n", " 'kid3_5_encoded',\n", " 'kid6_10_encoded',\n", " 'kid11_15_encoded',\n", " 'kid16_17_encoded',\n", " 'creditcd_encoded']"]}}], "source": ["# Respuesta\n", "\n", "columns_for_model"]}, {"metadata": {}, "source": ["\n", "\n", "Son demasiadas variables para introducir al modelo. Calculamos la correlaci\u00f3n con las num\u00e9ricas originales (que no son categ\u00f3ricas indexadas)"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 15, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 15, "data": {"text/plain": ["[]"]}}], "source": ["# Respuesta\n", "\n", "df_corrs = df_many_steps.select([F.round(F.corr(F.col('churn'), F.col(c)), 2).alias(c) for c in original_numerical_columns])\n", "    \n", "[(x, df_many_steps.columns[i]) for i, x in enumerate(df_corrs.first()) if x>0.4]\n", "\n", "# The result is not conclusive, since any of the features is too correlated with our target to include it"]}, {"metadata": {}, "source": ["\n", "\n", "Hacemos un random forest para sacar la importancia de las variables con todas las disponibles:"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 16, "outputs": [], "source": ["# Respuesta\n", "\n", "vectorassembler = VectorAssembler(inputCols=columns_for_model, outputCol='for_feature_relevance_assembled')\n", "df_many_steps = vectorassembler.transform(df_many_steps)"]}, {"metadata": {}, "cell_type": "code", "execution_count": 17, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.classification import RandomForestClassifier\n", "\n", "rf = RandomForestClassifier(featuresCol='for_feature_relevance_assembled', labelCol='churn')\n", "\n", "rf_model = rf.fit(df_many_steps)"]}, {"metadata": {}, "cell_type": "code", "execution_count": 18, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 18, "data": {"text/plain": ["[('months', 0.19714504125473276),\n", " ('hnd_price', 0.07575455882922477),\n", " ('eqpdays', 0.05357906172201724),\n", " ('totcalls', 0.05001250995016435),\n", " ('mou_mean', 0.0355266145408016),\n", " ('avg3mou', 0.028839542039690292),\n", " ('totmrc_mean', 0.021585782702271208),\n", " ('change_mou', 0.0207012986012553),\n", " ('mou_cvce_mean', 0.019144052513190256),\n", " ('ovrmou_mean', 0.01727186043264665),\n", " ('lor', 0.016386890819140035),\n", " ('totmou', 0.016170383807543813),\n", " ('iwylis_vce_mean', 0.015583457504144315),\n", " ('avg3qty', 0.014135811066364976),\n", " ('adjrev', 0.014048330975594265),\n", " ('mou_opkv_mean', 0.013764017725986417),\n", " ('adjqty', 0.012453512284686535),\n", " ('mouiwylisv_mean', 0.012433833016508614),\n", " ('vceovr_mean', 0.01042596190542066),\n", " ('opk_vce_mean', 0.010249712941547855),\n", " ('totrev', 0.009485604345871123),\n", " ('mou_peav_mean', 0.008818422458762585),\n", " ('avgqty', 0.00859510402168404),\n", " ('adjmou', 0.008216079726430594),\n", " ('avg6qty', 0.00792190722928188),\n", " ('custcare_mean', 0.007814044217889931),\n", " ('comp_vce_mean', 0.007653469298123454),\n", " ('complete_mean', 0.007167061321954079),\n", " ('unan_vce_mean', 0.0066906151900573965),\n", " ('mouowylisv_mean', 0.006013857196778889),\n", " ('owylis_vce_mean', 0.006010865861227207),\n", " ('ovrrev_mean', 0.005842371589311552),\n", " ('change_rev', 0.005756272395934207),\n", " ('avgmou', 0.005728354945299573),\n", " ('da_mean', 0.005039904246098999),\n", " ('ccrndmou_mean', 0.005030660760652042),\n", " ('models', 0.004870159097758928),\n", " ('plcd_vce_mean', 0.004717809638709764),\n", " ('rev_mean', 0.004620059438759986),\n", " ('drop_blk_mean', 0.003794269510597128),\n", " ('avg3rev', 0.0037896000660136977),\n", " ('inonemin_mean', 0.0032426583182526623),\n", " ('peak_vce_mean', 0.003080932800678388),\n", " ('attempt_mean', 0.0030730699219869108),\n", " ('avg6rev', 0.003018056884609705),\n", " ('avg6mou', 0.0029826484405719054),\n", " ('avgrev', 0.0028078631174082826),\n", " ('recv_vce_mean', 0.0027070963111517203),\n", " ('mou_rvce_mean', 0.002573135130494236),\n", " ('actvsubs', 0.002471297065180628),\n", " ('prizm_social_one_encoded', 0.0023393842144233965),\n", " ('drop_vce_mean', 0.0022285739392489718),\n", " ('cc_mou_mean', 0.002132762508893695),\n", " ('comp_dat_mean', 0.0019217158380691348),\n", " ('threeway_mean', 0.0018674005708198865),\n", " ('income', 0.0017407720660963383),\n", " ('peak_dat_mean', 0.001623894986004265),\n", " ('phones', 0.0015480323118491224),\n", " ('uniqsubs', 0.0014929457994942972),\n", " ('mou_opkd_mean', 0.0013895813816375132),\n", " ('mou_cdat_mean', 0.0011669237956391067),\n", " ('roam_mean', 0.001131105143485233),\n", " ('hnd_webcap_encoded', 0.0007967272347130432),\n", " ('callwait_mean', 0.000758248844018411),\n", " ('datovr_mean', 0.0006953814152444442),\n", " ('area_encoded', 0.0006455560080844436),\n", " ('plcd_dat_mean', 0.0005075972105882166),\n", " ('refurb_new_encoded', 0.000503919703043384),\n", " ('drop_dat_mean', 0.0004745173299349542),\n", " ('marital_encoded', 0.0004419090496350478),\n", " ('new_cell_encoded', 0.0004150587471047001),\n", " ('truck', 0.00036994732328048433),\n", " ('opk_dat_mean', 0.0003186717557306807),\n", " ('numbcars', 0.00030587383090374654),\n", " ('blck_dat_mean', 0.00027503167739342875),\n", " ('recv_sms_mean', 0.00026308953366693664),\n", " ('blck_vce_mean', 0.00025823431041156145),\n", " ('ownrent_encoded', 0.00019854273893059497),\n", " ('kid0_2_encoded', 0.0001912064991998418),\n", " ('unan_dat_mean', 0.0),\n", " ('mou_pead_mean', 0.0),\n", " ('callfwdv_mean', 0.0),\n", " ('rv', 0.0),\n", " ('adults', 0.0),\n", " ('forgntvl', 0.0),\n", " ('crclscod_encoded', 0.0),\n", " ('asl_flag_encoded', 0.0),\n", " ('dualband_encoded', 0.0),\n", " ('dwlltype_encoded', 0.0),\n", " ('infobase_encoded', 0.0),\n", " ('hhstatin_encoded', 0.0),\n", " ('dwllsize_encoded', 0.0),\n", " ('ethnic_encoded', 0.0),\n", " ('kid3_5_encoded', 0.0),\n", " ('kid6_10_encoded', 0.0),\n", " ('kid11_15_encoded', 0.0),\n", " ('kid16_17_encoded', 0.0),\n", " ('creditcd_encoded', 0.0)]"]}}], "source": ["# Respuesta\n", "\n", "feature_importances = [x for x in zip(columns_for_model, rf_model.featureImportances.toArray().tolist())]\n", "feature_importances.sort(key=lambda x: x[1], reverse=True)\n", "feature_importances"]}, {"metadata": {}, "cell_type": "code", "execution_count": 19, "outputs": [], "source": ["# Respuesta\n", "\n", "columns_for_model=['eqpdays', 'months', 'change_mou', 'hnd_price', 'adjrev', 'totmrc_mean', \n", "                   'avg3qty', 'mou_cvce_mean', 'avg3mou', 'mou_mean']"]}, {"metadata": {}, "source": ["\n", "\n", "Primera aproximaci\u00f3n para crear un modelo: crear obligatorio VectorAssembler, dividir los datos en train y test y entrenar la primera versi\u00f3n con hipermar\u00e1metros por defecto. Seleccionaremos las 10 variables m\u00e1s importantes. Despu\u00e9s evaluaremos nuestro modelo (usaremos accuracy)"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 20, "outputs": [], "source": ["# Respuesta\n", "\n", "vector_assembler = VectorAssembler(inputCols=columns_for_model, outputCol='assembled_features')\n", "df_many_steps = vector_assembler.transform(df_many_steps)\n", "\n", "df_many_steps_train, df_many_steps_test = df_many_steps.randomSplit([0.8,0.2])\n", "\n", "rf = RandomForestClassifier(featuresCol=vector_assembler.getOutputCol(), labelCol=target_column)\n", "rf_model = rf.fit(df_many_steps_train)\n", "df_many_steps_prediction = rf_model.transform(df_many_steps_test)"]}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 21, "outputs": [], "source": ["# Respuesta\n", "\n", "evaluator = MulticlassClassificationEvaluator(predictionCol=rf.getPredictionCol(),\n", "                                              labelCol=rf.getLabelCol(),\n", "                                             metricName=\"accuracy\")"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 22, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 22, "data": {"text/plain": ["0.6073427724728351"]}}], "source": ["# Respuesta\n", "\n", "evaluator.evaluate(df_many_steps_prediction)"]}, {"metadata": {}, "source": ["\n", "\n", "Podemos ver el n\u00famero de \u00e1rboles de nuestro random forest usando el atributo getNumTrees"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 23, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 23, "data": {"text/plain": ["20"]}}], "source": ["# Respuesta\n", "\n", "rf_model.getNumTrees"]}, {"metadata": {}, "source": ["\n", "\n", "Pero, \u00bfpodemos afirmar que este modelo fue entrenado con los mejores hiperpar\u00e1metros? Se podr\u00edan listar muchas combinaciones de ellos, lo que significa mucho trabajo manual. Pero no hay que preocuparse, para manejar esta situaci\u00f3n Spark incorpora **ParamGrid**. \n", "\n", "S\u00f3lo hay que definir los valores de cada hiperpar\u00e1metro que queremos probar en ParamGridBuilder y utilizar el objeto resultante en el par\u00e1metro `estimatorParamMaps` cuando se define el CrossValidator.\n", "\n", "En este caso, probaremos todas las combinaciones de:\n", "\n", "- Number of trees: [10,50,100,200]\n", "- Max depth: [3, 5, 7]"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 24, "outputs": [], "source": ["# Respuesta\n", "\n", "grid = ParamGridBuilder().addGrid(rf.numTrees, [10,50,100,200]) \\\n", "                                .addGrid(rf.maxDepth, [3,5,7]) \\\n", "                                .addGrid(rf.impurity, ['gini', 'entropy']) \\\n", "                                .build()\n", "rf_cv = CrossValidator(estimator=rf, \n", "                       estimatorParamMaps=grid, \n", "                       evaluator=evaluator, \n", "                       numFolds=3)\n", "rf_cv_model = rf_cv.fit(df_many_steps_train)\n", "\n", "# In the attribute bestModel we have the best model after trying all the possible combinations of \n", "# hyperparameter values in a random forest, using accuracy as our metric and doing cross validation with 3 folds\n", "bestModel = rf_cv_model.bestModel"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 25, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 25, "data": {"text/plain": ["10"]}}], "source": ["# Respuesta\n", "\n", "bestModel.getNumTrees"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 26, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 26, "data": {"text/plain": ["0.6073427724728351"]}}], "source": ["# Respuesta\n", "\n", "evaluator.evaluate(df_many_steps_prediction)"]}, {"metadata": {}, "source": ["\n", "\n", "# Ejercicio 1\n", "\n", "Dado el siguiente DataFrame:"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 27, "outputs": [{"output_type": "stream", "text": ["root\n", " |-- Time: decimal(10,0) (nullable = true)\n", " |-- V1: double (nullable = true)\n", " |-- V2: double (nullable = true)\n", " |-- V3: double (nullable = true)\n", " |-- V4: double (nullable = true)\n", " |-- V5: double (nullable = true)\n", " |-- V6: double (nullable = true)\n", " |-- V7: double (nullable = true)\n", " |-- V8: double (nullable = true)\n", " |-- V9: double (nullable = true)\n", " |-- V10: double (nullable = true)\n", " |-- V11: double (nullable = true)\n", " |-- V12: double (nullable = true)\n", " |-- V13: double (nullable = true)\n", " |-- V14: double (nullable = true)\n", " |-- V15: double (nullable = true)\n", " |-- V16: double (nullable = true)\n", " |-- V17: double (nullable = true)\n", " |-- V18: double (nullable = true)\n", " |-- V19: double (nullable = true)\n", " |-- V20: double (nullable = true)\n", " |-- V21: double (nullable = true)\n", " |-- V22: double (nullable = true)\n", " |-- V23: double (nullable = true)\n", " |-- V24: double (nullable = true)\n", " |-- V25: double (nullable = true)\n", " |-- V26: double (nullable = true)\n", " |-- V27: double (nullable = true)\n", " |-- V28: double (nullable = true)\n", " |-- Amount: double (nullable = true)\n", " |-- Class: integer (nullable = true)\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "data = spark.read.csv(DATA_PATH+'data/creditcard.csv', sep=',', header=True, inferSchema=True)\n", "\n", "data.printSchema()"]}, {"metadata": {}, "source": ["\n", "\n", "1) Calcula las dimensiones del Data Frame"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 28, "outputs": [{"output_type": "stream", "text": ["284807\n", "31\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "N = data.count()\n", "D = len(data.columns)\n", "print(N)\n", "print(D)"]}, {"metadata": {}, "source": ["\n", "\n", "2) Determina las clases de la base de datos, y su proporci\u00f3n"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 29, "outputs": [{"output_type": "stream", "text": ["+-----+------+----------+\n", "|Class| count|Proportion|\n", "+-----+------+----------+\n", "|    1|   492|      0.17|\n", "|    0|284315|     99.83|\n", "+-----+------+----------+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "data.groupBy('Class').count()\\\n", "    .withColumn('Proportion',F.round(100*F.col('count')/N,2)).show()"]}, {"metadata": {}, "cell_type": "code", "execution_count": 30, "outputs": [{"output_type": "stream", "text": ["+-----+-----+\n", "|Class|count|\n", "+-----+-----+\n", "|    1|  492|\n", "|    0|  492|\n", "+-----+-----+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "one_df = data.filter(F.col('Class')==1)\n", "zeros_df = data.filter(F.col('Class')==0).limit(one_df.count())\n", "\n", "data = one_df.union(zeros_df)\n", "data.groupBy('Class').count().show()"]}, {"metadata": {}, "source": ["\n", "\n", "3) Calcula el numero de valores no nulos, media, desviacion estandar, minimo y maximo de cada variable."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 31, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 31, "data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>summary</th>\n", "      <th>Time</th>\n", "      <th>V1</th>\n", "      <th>V2</th>\n", "      <th>V3</th>\n", "      <th>V4</th>\n", "      <th>V5</th>\n", "      <th>V6</th>\n", "      <th>V7</th>\n", "      <th>V8</th>\n", "      <th>...</th>\n", "      <th>V21</th>\n", "      <th>V22</th>\n", "      <th>V23</th>\n", "      <th>V24</th>\n", "      <th>V25</th>\n", "      <th>V26</th>\n", "      <th>V27</th>\n", "      <th>V28</th>\n", "      <th>Amount</th>\n", "      <th>Class</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>count</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>...</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "      <td>984</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>mean</td>\n", "      <td>40460.3913</td>\n", "      <td>-2.4674030372100706</td>\n", "      <td>1.9053035968231362</td>\n", "      <td>-3.083884202829431</td>\n", "      <td>2.456780057740528</td>\n", "      <td>-1.5617259373325363</td>\n", "      <td>-0.5725839910410212</td>\n", "      <td>-2.7309033383431682</td>\n", "      <td>0.2610818513880641</td>\n", "      <td>...</td>\n", "      <td>0.3548982757919289</td>\n", "      <td>-0.04448149211405792</td>\n", "      <td>-0.0365289425895097</td>\n", "      <td>-0.04738043011343525</td>\n", "      <td>0.08757054553217883</td>\n", "      <td>0.02612046010575492</td>\n", "      <td>0.09618165650018667</td>\n", "      <td>0.027865303758426347</td>\n", "      <td>96.22459349593503</td>\n", "      <td>0.5</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>stddev</td>\n", "      <td>52607.97621895258</td>\n", "      <td>5.407122314226479</td>\n", "      <td>3.5961094277406067</td>\n", "      <td>6.4359049253853895</td>\n", "      <td>3.0427216170397475</td>\n", "      <td>4.202691637741724</td>\n", "      <td>1.80365716680006</td>\n", "      <td>5.863241960076915</td>\n", "      <td>4.850081053008372</td>\n", "      <td>...</td>\n", "      <td>2.787267047849961</td>\n", "      <td>1.145079823805901</td>\n", "      <td>1.1489601018179971</td>\n", "      <td>0.5866834793500018</td>\n", "      <td>0.6404192414977026</td>\n", "      <td>0.46829911219573406</td>\n", "      <td>1.0037324673667463</td>\n", "      <td>0.44295453165840837</td>\n", "      <td>240.1423970706583</td>\n", "      <td>0.5002542588519275</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>min</td>\n", "      <td>0</td>\n", "      <td>-30.552380043581</td>\n", "      <td>-12.1142127363483</td>\n", "      <td>-31.1036848245812</td>\n", "      <td>-4.51582435488105</td>\n", "      <td>-22.105531524316</td>\n", "      <td>-6.40626663445964</td>\n", "      <td>-43.5572415712451</td>\n", "      <td>-41.0442609210741</td>\n", "      <td>...</td>\n", "      <td>-22.7976039055519</td>\n", "      <td>-8.88701714094871</td>\n", "      <td>-19.2543276173719</td>\n", "      <td>-2.02802422921896</td>\n", "      <td>-4.78160552206407</td>\n", "      <td>-1.24392415371264</td>\n", "      <td>-7.26348214633855</td>\n", "      <td>-2.73388711897575</td>\n", "      <td>0.0</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>max</td>\n", "      <td>170348</td>\n", "      <td>2.13238602134104</td>\n", "      <td>22.0577289904909</td>\n", "      <td>3.77285685226266</td>\n", "      <td>12.1146718424589</td>\n", "      <td>11.0950886001596</td>\n", "      <td>6.47411462748849</td>\n", "      <td>5.80253735302589</td>\n", "      <td>20.0072083651213</td>\n", "      <td>...</td>\n", "      <td>27.2028391573154</td>\n", "      <td>8.36198519168435</td>\n", "      <td>5.46622995370963</td>\n", "      <td>1.21527882183022</td>\n", "      <td>2.20820917836653</td>\n", "      <td>3.06557569653728</td>\n", "      <td>3.05235768679424</td>\n", "      <td>1.77936385243205</td>\n", "      <td>3828.04</td>\n", "      <td>1</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>5 rows \u00d7 32 columns</p>\n", "</div>"], "text/plain": ["  summary               Time                   V1                  V2  \\\n", "0   count                984                  984                 984   \n", "1    mean         40460.3913  -2.4674030372100706  1.9053035968231362   \n", "2  stddev  52607.97621895258    5.407122314226479  3.5961094277406067   \n", "3     min                  0     -30.552380043581   -12.1142127363483   \n", "4     max             170348     2.13238602134104    22.0577289904909   \n", "\n", "                   V3                  V4                   V5  \\\n", "0                 984                 984                  984   \n", "1  -3.083884202829431   2.456780057740528  -1.5617259373325363   \n", "2  6.4359049253853895  3.0427216170397475    4.202691637741724   \n", "3   -31.1036848245812   -4.51582435488105     -22.105531524316   \n", "4    3.77285685226266    12.1146718424589     11.0950886001596   \n", "\n", "                    V6                   V7                  V8  \\\n", "0                  984                  984                 984   \n", "1  -0.5725839910410212  -2.7309033383431682  0.2610818513880641   \n", "2     1.80365716680006    5.863241960076915   4.850081053008372   \n", "3    -6.40626663445964    -43.5572415712451   -41.0442609210741   \n", "4     6.47411462748849     5.80253735302589    20.0072083651213   \n", "\n", "          ...                         V21                   V22  \\\n", "0         ...                         984                   984   \n", "1         ...          0.3548982757919289  -0.04448149211405792   \n", "2         ...           2.787267047849961     1.145079823805901   \n", "3         ...           -22.7976039055519     -8.88701714094871   \n", "4         ...            27.2028391573154      8.36198519168435   \n", "\n", "                   V23                   V24                  V25  \\\n", "0                  984                   984                  984   \n", "1  -0.0365289425895097  -0.04738043011343525  0.08757054553217883   \n", "2   1.1489601018179971    0.5866834793500018   0.6404192414977026   \n", "3    -19.2543276173719     -2.02802422921896    -4.78160552206407   \n", "4     5.46622995370963      1.21527882183022     2.20820917836653   \n", "\n", "                   V26                  V27                   V28  \\\n", "0                  984                  984                   984   \n", "1  0.02612046010575492  0.09618165650018667  0.027865303758426347   \n", "2  0.46829911219573406   1.0037324673667463   0.44295453165840837   \n", "3    -1.24392415371264    -7.26348214633855     -2.73388711897575   \n", "4     3.06557569653728     3.05235768679424      1.77936385243205   \n", "\n", "              Amount               Class  \n", "0                984                 984  \n", "1  96.22459349593503                 0.5  \n", "2  240.1423970706583  0.5002542588519275  \n", "3                0.0                   0  \n", "4            3828.04                   1  \n", "\n", "[5 rows x 32 columns]"]}}], "source": ["# Respuesta\n", "\n", "data.describe().toPandas()"]}, {"metadata": {}, "source": ["\n", "\n", "4) Convierte la columna \"Class\" a double"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 32, "outputs": [], "source": ["# Respuesta\n", "\n", "data = data.withColumn('Class',F.col('Class').astype('double'))"]}, {"metadata": {}, "source": ["\n", "\n", "5) Divide el dataset en train y test, y comprueba si se mantiene la proporcion de las clases."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 33, "outputs": [{"output_type": "stream", "text": ["train :\n", "+-----+-----+----------+\n", "|Class|count|Proportion|\n", "+-----+-----+----------+\n", "|  0.0|  349|      49.5|\n", "|  1.0|  356|      50.5|\n", "+-----+-----+----------+\n", "\n", "test : \n", "+-----+-----+----------+\n", "|Class|count|Proportion|\n", "+-----+-----+----------+\n", "|  0.0|  143|     51.25|\n", "|  1.0|  136|     48.75|\n", "+-----+-----+----------+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "data_train, data_test = data.randomSplit([0.7,0.3],seed=0)\n", "print(\"train :\")\n", "data_train.groupBy('Class').count()\\\n", "    .withColumn('Proportion',F.round(100*F.col('count')/data_train.count(),2)).show()\n", "print(\"test : \")\n", "data_test.groupBy('Class').count()\\\n", "    .withColumn('Proportion',F.round(100*F.col('count')/data_test.count(),2)).show()"]}, {"metadata": {}, "source": ["\n", "\n", "6) Determina las columnas a utilizar como entradas del modelo"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 35, "outputs": [], "source": ["# Respuesta\n", "\n", "vectorassembler = VectorAssembler(inputCols=[x for x in data.columns if x!='Class'], outputCol='for_feature_relevance_assembled')\n", "data = vectorassembler.transform(data)\n", "\n", "from pyspark.ml.classification import RandomForestClassifier\n", "\n", "rf = RandomForestClassifier(featuresCol='for_feature_relevance_assembled', labelCol='Class')\n", "\n", "rf_model = rf.fit(data)"]}, {"metadata": {}, "cell_type": "code", "execution_count": 36, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 36, "data": {"text/plain": ["[('Time', 0.46020842119743854),\n", " ('V12', 0.19002351140284945),\n", " ('V3', 0.05985659536567158),\n", " ('V11', 0.04851105989642065),\n", " ('V14', 0.0438213545008186),\n", " ('V4', 0.04261377093342171),\n", " ('V1', 0.03320995766363637),\n", " ('V2', 0.029447540044507642),\n", " ('V17', 0.020695199098059447),\n", " ('V21', 0.017221337935920657),\n", " ('V10', 0.01660435391236873),\n", " ('V7', 0.006497692380353545),\n", " ('V6', 0.006468735859061245),\n", " ('V16', 0.0048992331899589585),\n", " ('Amount', 0.0035837509838148617),\n", " ('V28', 0.0028329948700722037),\n", " ('V22', 0.0021869523270229368),\n", " ('V20', 0.002068634488723442),\n", " ('V25', 0.0019551124438291372),\n", " ('V19', 0.0013965528077369252),\n", " ('V26', 0.0013708544251635028),\n", " ('V9', 0.0013564620961224823),\n", " ('V23', 0.0012712421651141011),\n", " ('V8', 0.000892459791711719),\n", " ('V27', 0.0004128378044335263),\n", " ('V13', 0.00036063804930590814),\n", " ('V24', 0.00014317423660036173),\n", " ('V5', 8.957012986170879e-05),\n", " ('V15', 0.0),\n", " ('V18', 0.0)]"]}}], "source": ["# Respuesta\n", "\n", "feature_importances = [x for x in zip(data.columns, rf_model.featureImportances.toArray().tolist())]\n", "feature_importances.sort(key=lambda x: x[1], reverse=True)\n", "feature_importances"]}, {"metadata": {}, "cell_type": "code", "execution_count": 41, "outputs": [], "source": ["# Respuesta\n", "\n", "features = ['Time', 'V14', 'V12', 'V17', 'V11', 'V3', 'V10', 'V16', 'V2', 'V21', 'V4', 'Amount', 'V20', 'V6']"]}, {"metadata": {}, "source": ["\n", "\n", "7) Entrena una regresi\u00f3n logistica usando Pipeline y evalua el modelo resultante calculando la AUC, f1, la tasa de acierto y la matriz de confusi\u00f3n  para train y test."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 39, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.feature import StandardScaler\n", "from pyspark.ml.classification import LogisticRegression\n", "from pyspark.ml.pipeline import Pipeline\n", "\n", "assembler = VectorAssembler(inputCols=features,outputCol='features')\n", "standard = StandardScaler(inputCol='features',outputCol='standar') \n", "lr = LogisticRegression(featuresCol='standar',labelCol='Class')\n", "\n", "pipeline_lr = Pipeline(stages=[assembler, standard, lr])\n", "\n", "model_lr = pipeline_lr.fit(data_train)"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 42, "outputs": [{"output_type": "stream", "text": ["train auc :  1.0\n", "test auc  :  0.9976347182229536\n", "#####################################\n", "train f1  :  1.0\n", "test f1   :  0.9928324624249172\n", "#####################################\n", "train acc :  100.0\n", "test acc  :  99.2831541218638\n", "train Confusion matrix :\n", "+-----+----+----+\n", "|Class| 0.0| 1.0|\n", "+-----+----+----+\n", "|  0.0| 349|null|\n", "|  1.0|null| 356|\n", "+-----+----+----+\n", "\n", "test Confusion matrix  :\n", "+-----+----+---+\n", "|Class| 0.0|1.0|\n", "+-----+----+---+\n", "|  0.0| 141|  2|\n", "|  1.0|null|136|\n", "+-----+----+---+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n", "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n", "\n", "\n", "auc = BinaryClassificationEvaluator(labelCol='Class')\n", "acc = MulticlassClassificationEvaluator(labelCol='Class',metricName=\"accuracy\")\n", "f1  = MulticlassClassificationEvaluator(labelCol='Class',metricName=\"f1\")\n", "\n", "data_train_LR = model_lr.transform(data_train)\n", "data_test_LR = model_lr.transform(data_test)\n", "\n", "print(\"train auc : \", auc.evaluate(data_train_LR))\n", "print(\"test auc  : \", auc.evaluate(data_test_LR))\n", "print(\"#####################################\")\n", "print(\"train f1  : \" , f1.evaluate(data_train_LR))\n", "print(\"test f1   : \" , f1.evaluate(data_test_LR))\n", "print(\"#####################################\")\n", "print(\"train acc : \" , 100 * acc.evaluate(data_train_LR))\n", "print(\"test acc  : \" , 100 * acc.evaluate(data_test_LR))\n", "\n", "print(\"train Confusion matrix :\")\n", "data_train_LR.groupBy('Class').pivot('prediction').count().show()\n", "print(\"test Confusion matrix  :\")\n", "data_test_LR.groupBy('Class').pivot('prediction').count().show()"]}, {"metadata": {}, "source": ["\n", "\n", "8) Entrena un RandomForestClassifier usando Pipeline y evalua el modelo resultante calculando la AUC, la tasa de acierto y la matriz de confusi\u00f3n  para train y test."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 43, "outputs": [], "source": ["# Respuesta\n", "\n", "rf = RandomForestClassifier(featuresCol=assembler.getOutputCol(),labelCol='Class', maxDepth=2, numTrees=5)\n", "\n", "pipeline_rf = Pipeline(stages=[assembler, rf])\n", "model_rf = pipeline_rf.fit(data_train)"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 44, "outputs": [{"output_type": "stream", "text": ["train auc :  0.999903415859116\n", "test auc  :  0.9998971616618676\n", "#####################################\n", "train f1  :  0.997163177647445\n", "test f1   :  0.9928298818531793\n", "#####################################\n", "train acc :  99.71631205673759\n", "test acc  :  99.2831541218638\n", "train Confusion matrix :\n", "+-----+---+----+\n", "|Class|0.0| 1.0|\n", "+-----+---+----+\n", "|  0.0|349|null|\n", "|  1.0|  2| 354|\n", "+-----+---+----+\n", "\n", "test Confusion matrix  :\n", "+-----+---+----+\n", "|Class|0.0| 1.0|\n", "+-----+---+----+\n", "|  0.0|143|null|\n", "|  1.0|  2| 134|\n", "+-----+---+----+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "data_tr02 = model_rf.transform(data_train)\n", "data_ts02 = model_rf.transform(data_test)\n", "\n", "print(\"train auc : \", auc.evaluate(data_tr02))\n", "print(\"test auc  : \", auc.evaluate(data_ts02))\n", "print(\"#####################################\")\n", "print(\"train f1  : \" , f1.evaluate(data_tr02))\n", "print(\"test f1   : \" , f1.evaluate(data_ts02))\n", "print(\"#####################################\")\n", "print(\"train acc : \" , 100*acc.evaluate(data_tr02))\n", "print(\"test acc  : \" , 100*acc.evaluate(data_ts02))\n", "\n", "print(\"train Confusion matrix :\")\n", "data_tr02.groupBy('Class').pivot('prediction').count().show()\n", "print(\"test Confusion matrix  :\")\n", "data_ts02.groupBy('Class').pivot('prediction').count().show()"]}, {"metadata": {}, "source": ["\n", "\n", "9) Utiliza una CV 5-fold con grid search para determinar los mejores parametros del RandomForestClassifier utilizando como metrica la f1. Prueba los parametros _maxDepth_ y _numTrees_."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": 45, "outputs": [], "source": ["# Respuesta\n", "\n", "paramGrid = ParamGridBuilder().addGrid(rf.maxDepth,[2,3])\\\n", "                              .addGrid(rf.numTrees,[2,3])\\\n", "                              .build()\n", "\n", "crossval_rf = CrossValidator(estimator=pipeline_rf,\n", "                          estimatorParamMaps=paramGrid,\n", "                          numFolds=5,evaluator = f1,seed = 0) \n", "\n", "model_cv_rf = crossval_rf.fit(data_train)"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 46, "outputs": [{"output_type": "stream", "text": ["train auc :  0.9999839026431859\n", "test auc  :  0.9964006581653639\n", "#####################################\n", "train f1  :  0.9971631205673759\n", "test f1   :  0.992831541218638\n", "#####################################\n", "train acc :  99.71631205673759\n", "test acc  :  99.2831541218638\n", "train Confusion matrix :\n", "+-----+---+---+\n", "|Class|0.0|1.0|\n", "+-----+---+---+\n", "|  0.0|348|  1|\n", "|  1.0|  1|355|\n", "+-----+---+---+\n", "\n", "test Confusion matrix  :\n", "+-----+---+---+\n", "|Class|0.0|1.0|\n", "+-----+---+---+\n", "|  0.0|142|  1|\n", "|  1.0|  1|135|\n", "+-----+---+---+\n", "\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "data_tr03 = model_cv_rf.transform(data_train)\n", "data_ts03 = model_cv_rf.transform(data_test)\n", "\n", "print(\"train auc : \", auc.evaluate(data_tr03))\n", "print(\"test auc  : \", auc.evaluate(data_ts03))\n", "print(\"#####################################\")\n", "print(\"train f1  : \" , f1.evaluate(data_tr03))\n", "print(\"test f1   : \" , f1.evaluate(data_ts03))\n", "print(\"#####################################\")\n", "print(\"train acc : \" , 100*acc.evaluate(data_tr03))\n", "print(\"test acc  : \" , 100*acc.evaluate(data_ts03))\n", "\n", "print(\"train Confusion matrix :\")\n", "data_tr03.groupBy(target).pivot('prediction').count().show()\n", "print(\"test Confusion matrix  :\")\n", "data_ts03.groupBy(target).pivot('prediction').count().show()"]}, {"metadata": {}, "source": ["\n", "\n", "10) Cuales son los valores de los parametros usados en el grid search"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 47, "outputs": [{"output_type": "stream", "text": ["Max Depth        :  2\n", "Num Trees        :  2\n", "Subsampling Rate :  1.0\n"], "name": "stdout"}], "source": ["# Respuesta\n", "\n", "best_rf_Model = model_cv_rf.bestModel.stages[-1]\n", "print(\"Max Depth        : \", best_rf_Model._java_obj.getMaxDepth())\n", "print(\"Num Trees        : \", best_rf_Model._java_obj.getNumTrees())\n", "print(\"Subsampling Rate : \", best_rf_Model._java_obj.getSubsamplingRate())"]}], "nbformat": 4, "nbformat_minor": 2}