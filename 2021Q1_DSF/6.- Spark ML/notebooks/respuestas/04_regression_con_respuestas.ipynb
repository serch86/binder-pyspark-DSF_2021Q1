{"metadata": {"language_info": {"pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "version": "3.5.2"}, "@webio": {"lastCommId": "359b4713c0ec4b149ad16c0fc2069df1", "lastKernelId": "49b0212b-4f85-49da-b42c-a02242f6cb07"}, "kernelspec": {"display_name": "d1-spark2python3", "language": "python", "name": "spark-python-d1-spark2python3"}, "toc": {"title_cell": "Table of Contents", "skip_h1_title": false, "number_sections": false, "toc_section_display": true, "base_numbering": 1, "toc_window_display": false, "toc_cell": false, "sideBar": true, "title_sidebar": "Contents", "toc_position": {}, "nav_menu": {}}}, "cells": [{"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["SANDBOX_NAME = ''# Sandbox Name\n", "DATA_PATH = \"/data/sandboxes/\"+SANDBOX_NAME+\"/data/data/\""]}, {"metadata": {}, "source": ["\n", "\n", "# Spark ML Problema de Regresi\u00f3n\n", "\n", "En este notebook abordaremos el problema de Machine Learning Supervisado de regresi\u00f3n. Trabajaremos con el dataset Boston Housing que contiene informaci\u00f3n sobre las diferentes caracter\u00edsticas de casas en la ciudad de Boston. Utilizaremos como variable objetivo el precio de las casas. Accederemos a este a trav\u00e9s de la librer\u00eda de ML de Python scikit-learn. Ajustaremos distintos modelos y compararemos los resultados obtenidos en \u00e9stos."], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "### Crear SparkSession\n", "Nota: en Datio no es necesario crear la sesi\u00f3n de Spark ya al iniciar un notebook con el kernel PySpark Python3 - Spark 2.1.0 se crea autom\u00e1ticamente."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "from pyspark.sql import SparkSession\n", "spark = SparkSession.builder.getOrCreate()"]}, {"metadata": {}, "source": ["\n", "\n", "### Cargamos los datos en un DataFrame de Spark\n", "Cargamos los datos de scikit-learn y los consolidamos en un DataFrame de Spark."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "import pandas as pd\n", "from sklearn.datasets import load_boston\n", "\n", "boston_dataset = load_boston()\n", "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n", "# We add the target variable to our Pandas DataFrame\n", "boston['MEDV'] = boston_dataset.target\n", "# We create a Spark DataFrame from the Pandas DataFrame\n", "boston = spark.createDataFrame(boston)\n", "boston.show()"]}, {"metadata": {}, "source": ["\n", "\n", "Vemos el schema."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "boston.printSchema()"]}, {"metadata": {}, "source": ["\n", "\n", "Podemos ver la descripci\u00f3n de las variables del objeto cargado de scikit-learn."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "print(boston_dataset.DESCR)"]}, {"metadata": {}, "source": ["\n", "\n", "### Pasos previos\n", "\n", "#### Vector Assembler\n", "Para ajustar un modelo en Spark necesitamos indicar qu\u00e9 variables se van a utilizar como variables independientes. A trav\u00e9s del par\u00e1metro _featuresCol_ de los distintos algoritmos, se le indica la variable que contiene la salida del  VectorAssembler con las variables independientes. \n", "\n", "Hacemos el VectorAssembler con todas las variables con excepcion del target."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "from pyspark.ml.feature import VectorAssembler\n", "\n", "variables_vector_assembler = list(set(boston.columns) - set(['MEDV'])) # We do not add the target variable\n", "vectorassembler = VectorAssembler(inputCols = variables_vector_assembler, outputCol = 'assembled_features')\n", "boston = vectorassembler.transform(boston)\n", "boston.show()"]}, {"metadata": {}, "source": ["\n", "\n", "#### Divisi\u00f3n train/test\n", "Realizamos la division train/test (o train/validation) para medir el desempe\u00f1o del modelo tras el ajuste."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "boston_train, boston_test = boston.randomSplit([0.8,0.2])"]}, {"metadata": {}, "source": ["\n", "\n", "### Regresi\u00f3n Lineal\n", "Modelo matem\u00e1tico usado para aproximar la relaci\u00f3n de dependencia entre una variable dependiente $Y$, las variables independientes $X_i$ y un t\u00e9rmino aleatorio $\u03b5$. Se expresa a traves de la siguiente ecuaci\u00f3n:\n", "\n", "$$Y = \\beta_0+\\beta_1*X_1+\\beta_2*X_2+...+\\beta_p*X_p+\u03b5$$\n", "\n", "donde \n", "- $Y$ es la variable dependiente, explicada o target,\n", "- $X_i$ son las variables explicativas, independientes o regresoras,\n", "- $\\beta_i$ son los parametros que miden la influencia que tienen las variables explicativas sobre el target,\n", "\n", "para todo $0<=i<=p$.\n", "\n", "Ajustamos un modelo de regresi\u00f3n y sacamos los valores reales y las predicciones."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "from pyspark.ml.regression import LinearRegression\n", "\n", "linear_regression = LinearRegression(featuresCol='assembled_features', labelCol='MEDV')\n", "linear_regression_model = linear_regression.fit(boston_train)\n", "boston_test_linear_regression = linear_regression_model.transform(boston_test)\n", "boston_test_linear_regression.select(['MEDV','prediction']).show()"]}, {"metadata": {}, "source": ["\n", "\n", "### Arbol de Decisi\u00f3n\n", "Modelo predictivo que se construye ejecutando una partici\u00f3n binaria recursiva de los datos identificando las variables y los puntos de corte de las mismas que mejor determinan el valor de la variable objetivo. En el entrenamiento son importantes los par\u00e1metros: medida de impureza y criterio de parada (normalmente profundidad).\n", "\n", "Ajustamos un \u00e1rbol de decisi\u00f3n para nuestro conjunto de datos y sacamos los valores reales y los predichos."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.regression import DecisionTreeRegressor\n", "\n", "decision_tree_regression = DecisionTreeRegressor(featuresCol='assembled_features', labelCol='MEDV')\n", "decision_tree_regression_model = decision_tree_regression.fit(boston_train)\n", "boston_test_decision_tree_regression = decision_tree_regression_model.transform(boston_test)\n", "boston_test_decision_tree_regression.select(['MEDV','prediction']).show()"]}, {"metadata": {}, "source": ["\n", "\n", "### Random Forest\n", "Modelo predictivo basado en \u00e1rboles de decisi\u00f3n. Construye varios \u00e1rboles tomando muestras del conjunto de datos (boosting) y muestras del conjunto de variables. Realiza la predicci\u00f3n para cada nuevo registro pasandolo por cada uno de los \u00e1rboles y promediando los resultados obtenidos.\n", "\n", "Ajustamos un random forest y obtenemos los valores reales y los predichos. "], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "from pyspark.ml.regression import RandomForestRegressor\n", "\n", "random_forest = RandomForestRegressor(featuresCol='assembled_features', labelCol='MEDV')\n", "random_forest_model = random_forest.fit(boston_train)\n", "boston_test_random_forest = random_forest_model.transform(boston_test)\n", "boston_test_random_forest.select(['MEDV','prediction']).show()"]}, {"metadata": {}, "source": [" \n", "\n", "# Evaluaci\u00f3n de modelos"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Para comparar el desempe\u00f1o de los modelos ajustados y poder seleccionar el mejor de ellos disponemos de diversas m\u00e9tricas. Algunas de ellas son:\n", "- Error cuadr\u00e1tico medio (MSE)\n", "- Ra\u00edz del error cuadr\u00e1tico medio (RMSE)\n", "- R cuadrado (R\u00b2)\n", "- Error absoluto medio (MAE)\n", "\n", "Como ejemplo obtenemos el RMSE y el MAE de los modelos ajustados."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.evaluation import RegressionEvaluator\n", "\n", "\"\"\" Possibilities::\n", "metric name in evaluation - one of:\n", "                       rmse - root mean squared error (default)\n", "                       mse - mean squared error\n", "                       r2 - r^2 metric\n", "                       mae - mean absolute error.\n", "\"\"\"\n", "\n", "rmse = RegressionEvaluator(predictionCol='prediction', labelCol='MEDV', metricName='rmse')\n", "mae = RegressionEvaluator(predictionCol='prediction', labelCol='MEDV', metricName='mae')"]}, {"metadata": {}, "source": ["\n", "\n", "Imprimir m\u00e9tricas para los distintos modelos"], "cell_type": "markdown"}, {"metadata": {"collapsed": false, "scrolled": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "print(\"RMSE for a linear regression: {}\".format(rmse.evaluate(boston_test_linear_regression)))\n", "print(\"RMSE for a decision tree: {}\".format(rmse.evaluate(boston_test_decision_tree_regression)))\n", "print(\"RMSE for a random forest: {}\\n\".format(rmse.evaluate(boston_test_random_forest)))\n", "\n", "print(\"MAE for a linear regression: {}\".format(mae.evaluate(boston_test_linear_regression)))\n", "print(\"MAE for a decision tree: {}\".format(mae.evaluate(boston_test_decision_tree_regression)))\n", "print(\"MAE for a random forest: {}\".format(mae.evaluate(boston_test_random_forest)))"]}, {"metadata": {}, "source": ["\n", "\n", "Observando los valores obtenidos en las m\u00e9tricas de evaluaci\u00f3n de modelos decidir\u00edamos quedarnos con el random forest."], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Podemos crear una funci\u00f3n que tenga como par\u00e1metros de entrada el dataframe transformado, la columna de predicci\u00f3n, y el target, y devuelva un diccionario con todas las m\u00e9tricas disponibles y sus respectivos valores."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["def calculate_metrics(dataset, predictionCol='prediction', labelCol='MEDV'):\n", "    \n", "    metrics = RegressionEvaluator(predictionCol=predictionCol, labelCol=labelCol)\n", "    \n", "    rmse = metrics.evaluate(dataset, {metrics.metricName: \"rmse\"})\n", "    mae = metrics.evaluate(dataset, {metrics.metricName: \"mae\"})\n", "    mse = metrics.evaluate(dataset, {metrics.metricName: \"mse\"})\n", "    r2 = metrics.evaluate(dataset, {metrics.metricName: \"r2\"})\n", "    \n", "    return {'rmse': rmse, 'mae':mae, 'mse': mse, 'r2':r2}"]}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["calculate_metrics(boston_test_linear_regression)"]}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["calculate_metrics(boston_test_decision_tree_regression)"]}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["calculate_metrics(boston_test_random_forest)"]}], "nbformat": 4, "nbformat_minor": 2}