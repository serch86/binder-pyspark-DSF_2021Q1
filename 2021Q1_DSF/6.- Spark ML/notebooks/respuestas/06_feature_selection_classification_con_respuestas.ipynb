{"metadata": {"language_info": {"pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "version": "3.5.2"}, "kernelspec": {"display_name": "d1-spark2python3", "language": "python", "name": "spark-python-d1-spark2python3"}, "toc": {"title_cell": "Table of Contents", "skip_h1_title": false, "number_sections": true, "toc_section_display": true, "base_numbering": 1, "toc_window_display": false, "toc_cell": false, "sideBar": true, "title_sidebar": "Contents", "toc_position": {}, "nav_menu": {}}}, "cells": [{"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["SANDBOX_NAME = ''# Sandbox Name\n", "DATA_PATH = \"/data/sandboxes/\"+SANDBOX_NAME+\"/data/\""]}, {"metadata": {}, "source": ["\n", "\n", "# Spark ML Selecci\u00f3n de Variables\n", "\n", "Cargamos un dataset con informaci\u00f3n sobre partos. Este dataset tiene como variable objetivo el fallecimiento o supervivencia de los reci\u00e9n nacidos."], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "### Crear SparkSession"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.sql import SparkSession\n", "\n", "spark = SparkSession.builder.getOrCreate()"]}, {"metadata": {}, "source": ["\n", "\n", "### Cargar datos y comprobar schema"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "births = spark.read.csv(DATA_PATH+'data/births_train.csv',sep=',', header=True, inferSchema=True) # You may try with: births.csv\n", "\n", "births.printSchema()"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "births.show(1)"]}, {"metadata": {}, "source": [" \n", "\n", "Se puede ver la variable objetivo (_target_) \"INFANT_ALIVE_AT_REPORT\" es de tipo \"string\".  Para realizar los siguientes an\u00e1lisis la misma debe ser convertida a tipo num\u00e9rico."], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "births.select('INFANT_ALIVE_AT_REPORT').distinct().show()"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.sql import functions as F\n", "from pyspark.sql.types import FloatType\n", "\n", "births= births.withColumn(\"INFANT_ALIVE_AT_REPORT\", F.udf(lambda x: 1.0 if x == \"Y\" else 0.0, FloatType())(\"INFANT_ALIVE_AT_REPORT\") )\n", "\n", "births.groupby(\"INFANT_ALIVE_AT_REPORT\").count().show()"]}, {"metadata": {}, "source": ["\n", "\n", "Todas las variables de tipo 'string' son categ\u00f3ricas. Hagamos un StringIndexer con ellas"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.feature import StringIndexer\n", "\n", "stringindexer_dictionary ={}\n"]}, {"metadata": {}, "source": ["\n", "\n", "Es una buena idea guardar todos los modelos para poder acceder a los cambios para cada categor\u00eda"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "for element in births.dtypes:\n", "    if element[1] == 'string':\n", "        stringindexer = StringIndexer(inputCol = element[0], outputCol=element[0]+'_indexed')\n", "        stringindexer_model = stringindexer.fit(births)\n", "        births = stringindexer_model.transform(births)\n", "        births = births.drop(element[0])\n", "        \n", "        stringindexer_dictionary[element[0]] = stringindexer_model"]}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "stringindexer_dictionary"]}, {"metadata": {}, "source": ["\n", "\n", "### ChiSquared\n", "\n", "Este m\u00e9todo de selecci\u00f3n de variables se aplica a variables categ\u00f3ricas."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.feature import ChiSqSelector, VectorAssembler"]}, {"metadata": {}, "source": ["\n", "\n", "El primer paso es crear un VectorAssembler de las variables categ\u00f3ricas"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "input_cols = [element for element in births.columns if '_indexed' in element]\n", "\n", "vectorassembler = VectorAssembler(inputCols=input_cols, outputCol='categorical_assembled')\n", "births = vectorassembler.transform(births)"]}, {"metadata": {}, "source": ["\n", "\n", "Chi Squared selector"], "cell_type": "markdown"}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "chisquared = ChiSqSelector(featuresCol=vectorassembler.getOutputCol(), labelCol=\"INFANT_ALIVE_AT_REPORT\", numTopFeatures=5)\n", "chisquared_model = chisquared.fit(births)"]}, {"metadata": {}, "source": ["\n", "\n", "Ver resultado:"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "chisquared_model.selectedFeatures"]}, {"metadata": {}, "source": ["\n", "\n", "Ver nombre de las variables:"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Nota: el orden viene dado por el orden en que se han introducido las variables en el VectorAssembler."], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "top_5_categorical = [input_cols[index] for index in chisquared_model.selectedFeatures]\n", "top_5_categorical"]}, {"metadata": {}, "source": ["\n", "\n", "### RandomForest\n", "\n", "Este m\u00e9todo toma tanto variables categ\u00f3ricas como num\u00e9ricas. Tiene el incoveniente que es aleatorio (_random_) y los resultados pueden verse modificados. Vamos a ver como contrarrestar este problema. Adem\u00e1s, retorna importancia de las variables."], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Importamos RandomForestClassifier puesto que se trata de un problema de clasificaci\u00f3n"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "from pyspark.ml.classification import RandomForestClassifier"]}, {"metadata": {}, "source": ["\n", "\n", "Para empezar, seleccionamos todas las variables menos la objetivo y la columna vector. Luego debemos volver a crear un VectorAssembler y ejecutamos el algoritmo RandomForestClassifier."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "features_for_rf = [element for element in births.columns if element != 'INFANT_ALIVE_AT_REPORT' and element !='categorical_assembled']"]}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "vectorassembler = VectorAssembler(inputCols=features_for_rf, outputCol='assembled_rf')\n", "births = vectorassembler.transform(births)\n", "\n", "rf = RandomForestClassifier(featuresCol=vectorassembler.getOutputCol(), labelCol='INFANT_ALIVE_AT_REPORT')\n", "\n", "rf_model = rf.fit(births)"]}, {"metadata": {}, "source": ["\n", "\n", "De nuevo, el \u00edndice del vector viene dado por el orden de entrada de las variables en el VectorAssembler"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "rf_model.featureImportances"]}, {"metadata": {}, "source": ["\n", "\n", "* Ordenamos importancias para quedarnos con las variables que explican el x% de importancia respecto la variable objetivo. Tomaremos el 95% de importancia"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Primero, creamos una lista y almacenamos el \u00edndice para poder recuperar el nombre de la variable m\u00e1s adelante\n"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "importances = [(index, value) for index, value in enumerate(rf_model.featureImportances.toArray().tolist())]"]}, {"metadata": {}, "source": ["\n", "\n", "Ordenamos de mayor a menor importancia"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "importances = sorted(importances, key=lambda value: value[1], reverse=True)"]}, {"metadata": {}, "source": ["\n", "\n", "Nos quedamos con aquellas que explican el 95% de las variables"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "compt = 0\n", "important_features =[]\n", "for element in importances:\n", "    if compt < 0.95:\n", "        compt += element[1]\n", "        important_features.append((features_for_rf[element[0]], element[1]))"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "important_features"]}, {"metadata": {}, "source": ["\n", "\n", "Ahora, veamos como evitar la aleatoriedad del RandomForest haciendo varias iteraciones y qued\u00e1ndonos con las variables que aparecen en todas las iteraciones"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Creemos una semilla (_seed_), al inicializarlo ser\u00e1 replicable."], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "random_seed = 4\n", "num_iter = 10\n", "\n", "import random"]}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "def feature_importance_RF(random_seed, featuresCol, featuresCols, labelCol, df):\n", "    rf = RandomForestClassifier(featuresCol=featuresCol, labelCol=labelCol, seed = random_seed )\n", "    rf_model = rf.fit(df)\n", "    \n", "    importances = [(index, value) for index, value in enumerate(rf_model.featureImportances.toArray().tolist())]\n", "\n", "    #order from highest to lowest importance\n", "    importances = sorted(importances, key=lambda value: value[1], reverse=True)\n", "\n", "    #select those that explain 95% of the target variable\n", "\n", "    compt = 0\n", "    important_features =[]\n", "    for element in importances:\n", "        if compt < 0.95:\n", "            compt += element[1]\n", "            important_features.append((featuresCols[element[0]], element[1]))\n", "    return important_features"]}, {"metadata": {}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "random.seed(random_seed)\n", "\n", "random_seeds=[]\n", "\n", "while len(set(random_seeds)) < num_iter:\n", "    random_seeds.append(random.randint(0,10000))\n", "\n", "features_random_seed = []\n", "for random_seed in random_seeds:\n", "    features_random_seed.append(feature_importance_RF(random_seed, vectorassembler.getOutputCol(), features_for_rf,'INFANT_ALIVE_AT_REPORT', births))"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "features_random_seed"]}, {"metadata": {}, "source": ["\n", "\n", "Tras construir esta lista de listas con informaci\u00f3n de cada iteraci\u00f3n, nos quedamos con aquellas variables que aparecen en cada iteraci\u00f3n. Veamos c\u00f3mo se hace."], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n", "\n", "Primero convertimos la lista de listas en una sola lista"], "cell_type": "markdown"}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "flat_features = [feature for one_seed in features_random_seed for feature in one_seed]\n", "features = [element[0] for element in flat_features]\n", "\n", "from collections import Counter\n", "\n", "features_all_seeds = [element[0] for element in Counter(features).items() if element[1] == num_iter]\n", "features_all_seeds"]}, {"metadata": {}, "source": ["\n", "\n", "Si quisi\u00e9ramos el valor de la importancia en s\u00ed, calculamos media por cada semilla:"], "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "import numpy as np\n", "\n", "dictionary_importances = {}\n", "\n", "for feature in features_all_seeds:\n", "    dictionary_importances[feature] = []\n", "    for values in features_random_seed:\n", "        for element in values:\n", "            if element[0] == feature:\n", "                dictionary_importances[feature].append(element[1])\n", "                break\n", "    dictionary_importances[feature] = np.mean(dictionary_importances[feature])"]}, {"metadata": {"collapsed": false}, "cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Respuesta\n", "\n", "sorted(dictionary_importances.items(), key=lambda value: value[1], reverse=True)"]}], "nbformat": 4, "nbformat_minor": 2}